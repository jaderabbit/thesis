%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Swarm Robotics}
\label{chap:first}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%Explain what the chapter focusses on. Be brief, and only focus on the main theme of the chapter. Also reference any previous chapters that link to the theme of this chapter.

%Then, outline the remaining sections and what each covers in a broad sense. Use labeled references like these: Section~\ref{sec:first:first_sec}, Section~\ref{sec:first:second_sec} and Section~\ref{sec:first:summary}. Note that all labels in this document follow a convention, but you are free to choose whatever labels you want to.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{What is Swarm Robotics?}
\label{sec:first:definitionswarmrobotics}

Swarm robotics is the study of the co-coordination of large numbers of relatively simple robots in order to perform a single function, without the existence of central control. Swarm robotics focuses on how to create robotic algorithms that result in the emergence of a desired complex behaviour\cite{csahin2005swarm}.

Swarm robotics typically draws inspiration from the observation of social insects: ants \cite{hoff2010two}, cockroaches \cite{garnier2005aggregation} and bees \cite{lee2012foraging} who exhibit collective behaviour in the growth and maintenance of their societies\cite{wilson1971insect, bailishive}. The more interesting aspects of insect societies such as foraging and collective transport can be studied and modeled in order to achieve the similar of behaviour in a group of robot. Swarm robotics also draws on concepts from other societies such as amoeba's aggregation into slime \cite{schmickl2007navigation} and communication, propulsion and sensing in bacteria \cite{dhariwal2004bacterium,martel2010using}. Social insect societies exhibit desired qualities of a robot swarm namely robustness, scalability and flexibility that are desired by a group of robots.

Drawing from this inspiration from social insects, swarm robotics algorithms have a number of characteristics that distinguish them from other robotics algorithms. The characteristics are as follows:

\begin{enumerate}

\item \textbf{Quantity}: Studies are regularly focused with scalability as a potential characteristic of swarm robotics algorithms even if real-robot experimentation is limited to only a few individuals. In order to test the scalability of an algorithm, models or simulations are often built for experimentation purposes. Erol Sahin proposes that 10 individuals is a reasonable lower bound for number of robots to be considered as swarm \cite{csahin2005swarm}. A group of robots with less than 10 robots, is considered just that - a group of robots. 

\item \textbf{Homogeneity}: A group of that has too many robots with individual characteristics, is no longer considered a swarm, since it would likely violate the robustness requirements. Loosing a specific robot that is the only individual of its kind capable of performing a specific function would mean the swarm no longer can perform that function and is therefore, no longer robust. It is of the author's opinion that heterogeneity can exist in swarm robotics provided that the redundancy of each type of robot in the swarm is high enough, or if the failure of that specific robot can be compensated, even if only to a lesser efficiency, by the remaining types of robot. The evaluation of homogeneity of a swarm of robots has been discussed and a potential measure to evaluating homogeneity is proposed in \cite{balch2000hierarchic}

\item \textbf{Decentralization and Autonomy}: There should be no single point of failure in the group of robots and the robots must have complete self-control of their actuation and sensors, without central control. The decentralization and autonomy of the robots is key in the robustness of the system. If a particular process requires a single leader to make decision, such a process should include the ability to detect the situation when there is no longer a leader, due to malfunction or destruction, and then re-elect a new leader without human intervention.

\item \textbf{Localization}: Local sensory and communication abilities are required in order to uphold decentralization requirement. Failure of global sensors and communication capabilities will effect the entire swarm dependant on it, thus violating decentralization. 

\item \textbf{Simplicity}: A single robot used should be under-equipped to handle the task by itself, but the collaboration of a group of the same robots should assist the completion of the task. In the author's opinion, the level of simplicity of robots is a topic worth debating since "simple" is a relative term and various complexities of robots have been used in swarms. For example, the kilobot project \cite{rubenstein2012kilobot} has built very low cost simple robots to enable one to test collective behaviours on very large swarms. The kilobots do not even have wheels for motion but simply have a set of 3 rigid legs with vibration motors for actuation. Sensors are limited in the form of a simple ambient light sensor and an infrared transmitter and receiver, and colored LED lights for communication. 

On the other side of the spectrum, Melliner et al \cite{mellinger2013cooperative,kushleyev2013towards} explore robotics algorithms for swarms of relatively advanced, expensive quadcoptors with a variety of top-class sensors such as magnetometers, accelerometers, gyros, barometer for altitude sensing and two Zigbee transceivers for communication.
\end{enumerate}

 The field of swarm robotics has been applied to a large variety of problems such as search and rescue \cite{mondada2002search}, item or garbage collection \cite{balch1995io}, autonomous inspection of machinery \cite{correll2007challenging}, military formations for military application \cite{balch1998behavior}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{History}
\label{history}
 
%TODO: Turn into an introduction. 
Swarm robotics is simply the latest buzzword for a concept that has been of interest since the 1980s and has gone by many other names in the past. Early swarm robotics research explored the use of robots as a tool with which to model and validate entomology research on social insects \cite{dorigo2014swarm, beni1993swarm, seeley2009wisdom}.

This section aims to briefly highlight the history of swarm robotics and it's progress by addressing behaviour based robotics, the origins of multi-robot systems and other early research.

\subsection{Journey from Classic Robotics}
\label{journeyfromtraditionalAI}

It is plausible that the first step in the movement from symbol-based classical robotics to swarm robotics was the movement from complex symbolic systems towards more simpler architectures which began in the mid-to-late 1980s. In Rodney A. Brooks' iconic paper "Elephants don't play chess" \cite{brooks1990elephants}, the movement from traditional artificial intelligence towards what they brand "nouvelle" artificial intelligence is discussed. Brooks explains that traditional symbol-based classical artificial intelligence made certain assumptions about how intelligence worked and those assumptions actually impeded that form of artificial intelligence. 

Brooks presents the physical grounding hypothesis which is the idea that intelligence is composed of individual modules that generate behaviour and the co-existence and co-operation of these modules allow for the emergence of complex behaviour. The physical grounding hypothesis states that the world is it's own best model and thus in order to accurately make decisions about the real world, one should add sensing and actuating capabilities to artificial intelligence agents.

On the other hand, classical AI side makes use of the symbol system hypothesis which states that all intelligence operates using symbols with the implication that symbols represent all world entities which fails in the fact that these symbols may not be up to date with the environment or have the ability to represent unseen things. 

The physical grounding hypothesis lead to the development of behaviour-based robotics and more concretely the subsumption architecture \cite{brooks1986robust} by tightly connecting perception to action. A subsumption program organises finite state machines into a layered incremental networks. 

Multiple robotic systems were developed using the subsumption architecture with great success. Allen, a robot that has 3 layers of behaviours: a obstacle avoidance layer, a random wandering layer as well as search for the furthest point layer. These 3 separate behaviours cause the robot to adequately explore an environment \cite{brooks1986robust}.

Herbert, the soda can collector robot, was a notable development since Herbert was required to complete the significantly more complex task of search for and picking up empty soda cans from people desks \cite{connell1989colony}. To solve the problem, 15 individual behaviours were developed, with no communication between the behaviour generating modules. Other subsumption implementations include Toto \cite{mataric1990distributed}, Squirt \cite{flynn1989world} and Genghis \cite{brooks1989robot}

The key feature that can be determined by the success of physically grounded systems is that interactions of simpler non-goal directed behaviour results in emergence of goal-directed behaviour. Ronald Arkin discusses the idea that behaviour-based robotics imposes a biologically bottom up approach with the need that intelligence must be reactive to the dynamic environment and that intelligence needs to generate robust results despite noisy complex real world environment \cite{arkin1990integrating}.

The movement towards simplicity of controllers in the form of subsumption architecture and the feature of emergence perhaps inspired the step from single subsumption architecture robots to multi-robot systems. Most work in swarm robotics began after the introduction of behaviour-based robotics paradigm \cite{arai2002editorial}

\subsection{Evolution of the term and early research}
\label{early-research}
%TODO: Make flow
%How to rearrange? Potentially remove?

Early research involving collaboration of multiple agents was originally a way of verifying entomology research on social insects \cite{dorigo2014swarm, beni1993swarm, seeley2009wisdom}. Multiple researchers modelled and simulated aspects of the insect colonies that were being studied, in order to learn more about their self organizational mechanisms. 

Extremely early work included modeling the excavation behaviour and tunnel creation of ants, to simulate the rate of excavation \cite{sudd1975model}. Agent simulation was used to validate a model about the spatial arrangement and diet overlap between colonies of desert ants \cite{ryti1984spatial} 

Seeley et al \cite{seeley1991collective} formulated a mathematical model of collective decision-making in bee colonies where digital simulations were used to determine validity of a model of collective foraging in bees based on individual behaviour rules \cite{de1998modelling}. Foraging behaviour of ants has also been simulated in early research \cite{lopez1987optimal}. Such studies discovered many of the features about social insects that are exploited in swarm robotics today.

From the late 1980s till the mid 1990s, swarm robotics research emerged under many different guises: Collective robotics \cite{kube1993collective}, cellular robotics \cite{freund1984design}, co-operative mobile robotics \cite{cao1997cooperative}, distributed robotics \cite{asama2013distributed}, multi-robot systems \cite{mataric1995cooperative}. It's difficult to determine which terms were used first as they seem to have been in use concurrently. Essentially all of these terms have converged to what we now know as swarm robotics.

In one of the earlier, more notable papers, Freund explores the design of the structure of multi-robot systems based on the nonlinear control approaches, which is demonstrated on the collision avoidance of two robots working on the same space \cite{freund1984design,freund1986pathfinding}. Around a similar time, multi-robot design paradigm ACTRESS was developed to also address the design of autonomous distributed robot systems \cite{asama1989design}. 

In the late 1980s and early 1990s, Fukuda et al \cite{fukuda1989communication,fukuda1990analysis} introduced work in the field of cellular or configurable robotics. Cellular robotics is a robotic system which can reconfigure itself based on dynamic environmental requirements. The idea is that cells of smaller, simpler robots can dock with each other to form a single compound structure that can more effectively handle the pressures of the new environment. The research predominantly explored how the distributed communication between the cells would work. Fukanda et al. evaluate and describe their CEBOT structure with an optimal knowledge allocation method to communicate between cells. 
Around the same time, Beni et al \cite{beni1991theoretical} explores which problems would have needed to be solved for cellular robotics to become feasible in real-world application.

The various ideas for the use of multiple robots to a achieve a task have now been grouped under the umbrella term of swarm robotics. Since the 1990s, swarm robotics has become a popular field of research in artificial intelligence that has peaked the interest of the world. 

\section{Motivations}
\label{sec:first:advantages}

Swarm robots draws inspiration from insect swarms due to the characteristics of robustness, flexibility, scalability and in a lesser way cost-effectiveness. The following sections describe the characteristics of insect swarms that all swarm robotics algorithms strive to achieve. 

\subsection{Robustness}
\label{robustness}


In swarm robotics, robustness is defined as the ability to continue to function despite failures or abnormalities of the respective individuals and environments. Three aspects of insect swarm algorithms have been identified as enabling robustness: redundancy, decentralized coordination, and multiplicity of sensing \cite{csahin2005swarm}.

Swarm robotics algorithms achieve redundancy by giving all or a portion of the robots the same capabilities. In this way, if a percentage of the swarm malfunctions, the other robots have the capability to take the malfunctioning robots place. The loss of a single individual is compensated by another.

Decentralized coordination can be attained by creating algorithms that do not depend on the life span of any single individual or few finite individuals of the swarm.

The use of a large number of individuals increases the total number of sensors.  As a result of sensory multiplicity, the total signal-to-noise ratio is increased. If the sensor data of the robot swarm is adequately aggregated by the swarm, the overall effect of noise can be decreased or eliminated. 

\subsection{Flexibility}

A swarm robotics algorithm should exhibit the ability to adapt and adjust to new or changing requirements. Ants and bees do this by having effective division of labour strategies. The individuals in many insect societies, such as ants and bees, can take on a variety of different roles required by the nest such as brooding, foraging or nest maintenance when requirements of the nest change \cite{morley1946division}. The ability to take on different roles when requirements change is known as division of labour \cite{beshers2001models}. Many swarm robotics algorithms make use of social insect-like division of labour in order to adapt to changing requirements such as \cite{labella2006division, liu2007towards, gerkey2004formal}. The use of division of labour assists the swarm in maintaining flexibility.

\subsection{Scalability}
Scalability refers to the ability of the robotic swarm to expand the self-organizational mechanism for larger problems easily by simply adding more robots to the swarm. The performance of the algorithm should not be negatively effected by an increase in swarm size, and an increase in swarm size should adequately improve the performance of the swarm. In order for an algorithm to be considered as a swarm robotics algorithm, scalability studies should be perform in order to determine whether an algorithms performance will increase at an adequate rate as the swarm size increases. Scalability studies have been performed in \cite{nouyan2008path,bahgecci2005evolving,zarzhitsky2005distributed}

\subsection{Cost-effectiveness}
This runs off the premise that multiple inexpensive robots are likely to be cheaper to buy and maintain than a single large more complex robot. Cost-effectiveness is a debatable attribute, which depends on the complexity of robotics required. 

\section{Current State of Swarm Robotics}

There are a number of axes of focus on swarm robotics research. The core dimensions of the field are modelling, behaviour design, communication, analytical studies and problems. This section discusses those core dimensions in order to give an overview of the current state of swarm robotics research. 

\subsection{Analysis}
Models are used to determine if a property of the swarm behaviour is true or not. Both macroscopic and microscopic modelling is very difficult due to the nature of self-organising systems so one technique is usually focused on at a time \cite{abbott2006emergence}. The next sections discuss the modelling techniques.

\subsubsection{Microscopic Models}
\label{microscopicmodels}

Microscopic models are concerned with individual agents and analyse interactions between each robot and between a robot and the robot's environment. Microscopic models are implemented to varying levels of detail - some are simplified to a 2D grid world environment where as others choose to opt for full 3D environment with dynamic physics. The level of detail is dependant on the problem and what is being researched.

Predominantly microscopic models take the form of simulators and are used to validate swarm robotics systems. Swarm-robotic specific simulators include Stage \cite{vaughan2008massively} and ARGoS \cite{pinciroli2011argos} which focus on simulating a large number of agents. A concern of obtaining and maintaining a large number of agents is one of the reasons why simulators are used in swarm robotics instead of real world experimentation.

\subsubsection{Macroscopic Models}
\label{macroscopicmodels}

Macroscopic models are focused on a higher level view of the entire system and the individuals of the system are not analysed. A variety of macroscopic models exist as follows: 
\begin{itemize}
	\item \textbf{Rate and differential equations} - Rate equations are used to describe the change in the proportion of robots in a particular state of robot total over time. Rate equations were used to model a variety of swarm robotics problems such as  clustering \cite{martinoli1999understanding}, stick pulling \cite{lerman2001macroscopic}, foraging \cite{lerman2002mathematical}, chain formation \cite{trianni2002modeling}, and multi-foraging \cite{campo2007efficient}. Limitations include that modelling space and time is complex as robots' position in space are not modelled explicitly and as a result, a robot could move from any part of the space to another.

Similarly differential equations have been used to model swarms and have the advantage of includng noise, stochasticity and spatiality however, these differential equations are often computationally expensive and complex to solve \cite{hamann2008framework, prorok2011multi}

	\item \textbf{Classical Control and stability theory} has been used to prove swarm properties \cite{gazi2005stability,liu2004stable, schwager2011time}. Classical control methods have the advantage of being based on sound mathematics, however they often rely on assumptions in order to simplify the modelling process. In reality, many of those assumptions are continuously violated.
	
	\item \textbf{Other methods}
	Many other mathematical modeling approaches have been used in a swarm robotics context such as linear time temporal logic to define safety and liveness of swarm individuals \cite{winfield2005formal}, probabilistic model checking to verify swarm properties \cite{konur2012analysing}, or using branching processes to model communication of a swarm of aerial robots \cite{mathews2010establishing}. 
\end{itemize}

\subsubsection{Real-robot analysis}

Since it is implausible to attempt to simulate reality completely, real robot experimentation is integral to validating the behaviour of the swarm. These simulations usually occur in controlled environments with the ability to control the level of noise and environmental disruption. 
The disadvantage of performing real robot analysis is that experimentation is generally more costly, complex and time consuming than simulation or modeling methods. The purpose of real robot analysis is to show that the prospective swarm behaviour is actually obtainable \cite{brambilla2013swarm}.

\subsection{Behaviour Design}

In order for to achieve emergent behaviours of the swarm, a number of approaches for the design of robot controllers have been used. This chapter addresses the techniques of behaviour design namely non-adaptive, learning and evolutionary approaches.

\subsubsection{Non-adaptive}
Non-adaptive behaviour design, in general, refers to techniques of behaviour design where by the algorithms have specifically been hand-crafted by the human designer. These techniques either utilize mathematical approaches or focus on how to combine simpler behaviours to achieve the desired emergent behaviour. 

\begin{itemize}
	\item \textbf{Subsumption} - The invention of subsumption architecture could have promoted the development of swarm robotics by simplifying the process of building robots, thus it is fitting that the individual robots are modelled using subsumption architecture. Each behaviour forms a separate module that can inhibit other behaviours. 
	
	\item \textbf{Probabilistic Finite State Automata} Probabilistic finite state automata are a method to represent dynamical systems with finite state spaces. Each behaviour is a state and transistions are defined between these states with some probabilities and external input \cite{soysal2005probabilistic,labella2004efficiency}. The algorithms addressed in this thesis take the form of probabilistic finite state automata.  
	
	\item \textbf{Distributed Potential Field Methods}
	All vector interactions are represented as vectors where vectors can be positive or negative. This approach is useful in building swarm behaviours that require spatial distribution between robots such as pattern formation or motion coordination. Examples of using distributed potential field methods can be seen in \cite{bennet2010distributed,barnes2007unmanned, kim2006decentralized}  
\end{itemize}

\subsubsection{Learning}

One can provide agents the tools in order to learn behaviours suited to solve certain problems. A number of techniques are used in order to learn behaviours, most notably reinforcement learning and classically trained neural networks. A neural network controller for swarms could plausibly be trained using back propagation, but is in general paired with a evolutionary technique in order to evolve the neural network appropriately as is described in the following section. 

\subsubsection{Evolution}
Neural network or tree-based controllers for swarms of robots can be evolved or optimized using a variety of algorithms from swarm to genetic techniques \cite{baldassarre2003evolving, tuci2014evolutionary}. Francesca et al define two evolutionary approaches AutoMoDe-Vanilla and EvoStick \cite{francesca2014automode,francesca2014experiment}. The experiments compared the effectiveness of evolving swarm robot controllers in comparison to human created controllers. The interesting result is that the evolved AutoMoDe-Vanilla controller was able to outperform the human created controller, thus showing the promise for using evolutionary techniques to design swarm controllers.

\subsection{Interactions}
A key element of swarm robotics is the interactions between robots in a swarm. Cao et al \cite{cao1997cooperative} classified the methods of information transfer between robots in their  survey on swarm robotics. Interactions were segmented into three types:
\begin{itemize}
	\item \textbf{Interaction via sensing} where no direct communication between robots occurs and robots simply obtain information from their senses, for instance the stick pulling problem whereby a robot can sense another robot pulling the stick \cite{ijspeert2001collaboration}. 
	\item \textbf{Interaction via environment} where the robots modify the environment in some way and then other robots perceive and understand that modification such as pheromones in ants. Robots have mimicked pheromone-like deposits in a number of ways.
	\item \textbf{Interaction via communication} implies that robots interact and transfer information by assigning meaning to specific signals or having a specific language. This language could be in the form of light signals or even direct data transfer via bluetooth.  
\end{itemize}

\subsection{Behaviours}
\label{swarmrobotapplications}

Brambilla et al \cite{brambilla2013swarm} present a taxonomy of swarm behaviours. These behaviours can be used as ingredients to solve more complex applications - most prominently in this study, foraging. The problems are discussed in more details in the next sections.

\subsubsection{Spatially Organizing Behaviours}
The following behaviours involve agents positioning themselves in their environment in relation to the position of other agents.

\begin{itemize}
	\item \textbf{Aggregation} Aggregation is the movement of individuals towards one another to form a cluster and has become one of the fundamental swarm behaviours. In nature, aggregation aids protection from predators, the ability to defend against an unfavourable environment and locate partners \cite{bonabeau2001self}. A variety of approaches to swarm robot aggregation have been investigated \cite{yan2011algorithm, soysal2007aggregation, trianni2003evolving, dimarogonas2008connectedness }. A more recent approach finds inspiration in honey bees \cite{schmickl2011beeclust, schmickl2009two}
	
	\item \textbf{Pattern formation}
	The goal of pattern formation is for deployed robots to maintain specific distances between each other in order to create a particular shape. Implementation usually utilizes virtual forces in order to co-ordinate positioning of the agents. A review can be found in \cite{bahceci2003review, hettiarachchi2009review}
	
	\item \textbf{Path formation} is the creation of chains of robots in order to connect two or more points. The robot chains can serve as pheromone paths in order to navigate other robots through environments as generally, robots are not equipped with pheromone sensors and deployers. Research in path formation forms part of environmental exploration and navigation \cite{nouyan2006chain}. 
	
	Path formation is useful as a navigational strategy is the swarm robotics context as traditional complex forms of navigation do not scale well with the number of robots involved. Path formation techniques also have the advantage of being more failure tolerant since they do not rely on a specific individual.
	
	Research in path formation initially had the robots emit a signal communicating their position. Unfortunately this sort of approach would have to tackle the problem of a robot localizing itself globally \cite{goss1992harvesting}. Later, experimentation was performed with path formation with real robots in a prey retrieval experiment where the robots used physical contact to sense each other \cite{werger1996robotic}. More recent approaches attempt to give directionality to the chains by giving the chains a cyclic directional pattern - the approach was tested with real robots to transport heavy objects \cite{nouyan2006group}. Path formation has been used to connect two objects that are too distanct from each other to be perceived at the same time by a robot \cite{nouyan2006chain}.

	\item \textbf{Self-assembly and morphogenesis}
	Ants can create connections to each other to pull large prey and build bridges or walls. Self-assembly is where individual robots connect in order to create a compound structure of robots. Self-assembly was a very early behavior of research in the swarm robotics field - originally known as cellular robotics. The idea is that each robot forms a single cell or what metaphorically equates to a multi-cellular organism. In application, self-assembly can be used to stabilize robots on difficult terrain, combine forces to transport another object \cite{brambilla2013swarm}. Self-assembly has remained one of the more complex behaviours, due to the challenge of morphogenesis and how to control the structure in a consistent manner.  
Reviews on self assembly are presented by Groß and Dorigo \cite{gross2008self}	
	
	\item \textbf{Object clustering and Assembling}
	The goal of clustering is to group similar objects close to each others and the goal of assembling to link objects in a required way. Approaches usually involve probabilistic finite state machines involving random walks across the environment and reaction towards available objects. Challenges in this field are to do with interference from robots and obstacles near the cluster site. A variety of implementations of clustering \cite{beckers1994local}, wall creation \cite{wawerla2002collective} and 2D and 3D structure creation \cite{werfel2006extended, werfel2011distributed} have been developed. 
\end{itemize}

\subsubsection{Navigation behaviours}
%TODO intro
Robot navigation is not a simple task. There is knowledge that could be gained by sharing information about navigation between robots. This section addresses types of navigation behaviours that swarm robots can use. 

\begin{itemize}
\item \textbf{Collective exploration}
Brambilla et al \cite{brambilla2013swarm} break collective exploration into two behaviors, namely area coverage and swarm-guided navigation. The goal of area coverage is to deploy robots with the aim of creating a grid of communicating robots over a space. Area coverage is usually approached by using virtual physical forces\cite{howard2002mobile,stirling2010energy}.
Swarm-guided navigation is simply to navigate an environment using swarms which is usually achieved using probabilistic finite state machines \cite{payton2001pheromone,ducatelle2011self}. Ants use pheromone trains and area coverage studied in wireless sensor networks \cite{brambilla2013swarm}. 
	
\item \textbf{Coordinated motion} 
enables robots to move together like a swarm of locusts, a school of fish or a flock of birds. Coordinated motion is similar to pattern formation and often uses similar mechanism as pattern formation such as virtual forces. Navigating effectively as a swarm reduces interference between agents, increases the safety of individuals and reduces energy consumption \cite{parrish2002self}. Research performed in this domain is focused around maintaining a constant distance between each robot as well as on a means of calculating the overall heading direction of the swarm \cite{turgut2008self,ferrante2010flocking,baldassarre2003evolving} 
	
Another problem that falls under collective motion would be hole avoidance \cite{trianni2006cooperative,trianni2005emergent} 

\item \textbf{Collective transport} has become a benchmark for swarm robotics since it is requires numerous collaborative aspects such as task allocation, coherence, conflict resolution and communication. Mataric et al use a simple communication protocol on real robots to compensate for noise-ridden sensing to use a group of robots to move a box \cite{mataric1995cooperative}. Hiroshi et al do not utilize explicit communication but rather allow robots to infer the intention of other robots via their behaviour, in order to enable the robots to correctly place desks in an environment. The study indicates the benefit of collaboration \cite{sugie1995placing}. Gerkey et al. implement a dynamic task allocation algorithm for a robot with an auction-based mechanism using publish/subscribe communication also to perform a box pushing exercise \cite{gerkey2002sold}. The SWARM-BOTS project involved substantial work with the s-bots. S-bot robots have the ability to link to each other. Experimentation showed that the chained s-bots were able to transport items more effectively \cite{gross2004group, dorigo2005swarm, ferrante2013socially}.

\end{itemize}
		
\subsubsection{Collective decision-making}
With any multi-agent system, the ability for the system to collectively make decisions is far more complicated system than in traditional robotics or more simplistic hive minds. The next section discusses and provides examples of types of collective decision making behaviours. 

\begin{itemize}
	\item \textbf{Consensus achievement} is the process of how a group of robots come to a decision among a variety of alternative choices in order to maximise system performance. This is observed in ant colonies to determine the shortest path \cite{bonabeau2001self} and is used by bees decide on the next best site for a nest \cite{seeley2001nest}
	
	\item \textbf{Division of Labour} - Division of labour occurs naturally in insect colonies \cite{gautrais2002emergent}, most notably in bees and ants.

Division of labour is a key primitive problem in swarm robotics. Most tasks require different behaviours in order to reach completion. The goal of division of labour is how resources can most effectively be assigned behaviours to optimally achieve the final goal. Division of labour is usually addressed as part of a more complex problem such as foraging.
 
A common division of labour problem addresses achieving the optimal quantity of robots performing an activity as opposed to resting. Too many robots performing a task may increase the number of collisions and thus decrease the overall efficiency or too many performing the tasks might just be wasting energy thus motivating the need to achieve effective division of labour between active and passive robots \cite{jones2003adaptive, krieger2000call}.

\end{itemize}

\section{Division of Labour}

\label{chap:divisionoflabour}
Due to the importance of division of labour in this research, a variety of division of labour strategies should be highlighted, explored and contrasted. This chapter defines division of labour as well as analyses different types of division of labour.

\subsection{Definition}
\label{sec:second:definition}

Oster et al. defines division of labour as a "stable pattern of variation" among individuals within a swarm in terms of the repertoire of tasks that individuals perform where each individual specializes on a subset of the complete repertoire of tasks performed by the swarm and the subset of tasks varies across individuals in the swarm \cite{oster1978caste}.  
More simply, Robinson et al. define division of labour as the adjustment of ratios of workers engaged in different tasks based on external and internal stimuli \cite{robinson1992regulation}.

There are two types of division of labour in social insects: 
\begin{itemize}
	\item Temporal polyethism - The pattern of tasks being performed by a worker correlates to the age of the worker. In nature, the younger workers may perform tasks within the nest while the older workers perform tasks outside of the nest.
	\item Morphological polyethism - A worker with some extreme features in terms of size or shape, will specialize more in particular tasks and the more extreme that feature is, the narrower the repertoire of the of the worker. In nature, for example, larger workers would be more likely to form part of defence of the nest. \cite{beshers2001models}
\end{itemize}

%NEED SOMETHING HERE

%include if we find we need. for now, you're done
%\subsubsection{Task Selection}
%Before addressing the different models of division of labour, it's important to discuss one of the main distringuishing characteristics of division of labour: How does an individual select tasks? Much of the study of division of labour is related to how workers select tasks. The factors contributing to the decision are divided into internal and external factors. Internal factors refer to neurological, hormonal, experience or genetic factors where as the external factors refer to environmental stimuli, worker to worker interaction and communication of the increasing need of workers assigned to a particular task. \cite{beshers2001models}.

%Research around task selection is focused around the following topics: 
%\begin{itemize}
%	\item The rules guiding the decision process in workers
%	\item The process of how information about the environment and social stimuli is gathered
%	\item The internal choice mechanism for making the decisions
%\end{itemize}

\subsection{Models of Division of Labour}

Beshers at al \cite{beshers2001models} provide a extensive overview of models of division of labour in insects. Due to the use of insect division of labour addressed by algorithms developed in this thesis, an overview of existing models is provided in the next section.

\subsubsection{Response Threshold Model}

In the response threshold model, workers have intrinsic thresholds for reacting to task-specific stimuli. The variation in task thresholds among workers in a swarm induces the division of labour \cite{robinson1992regulation}. The response threshold model identifies variation in the worker environment interaction as the primary reason for division of labour

Each task in the repertoire has a related response threshold. The default state of all workers is to have no task assigned. All workers have some threshold for a task and higher stimulus levels result in recruitment of additional workers into a task group. Specialist have the lowest thresholds for a particular task. A negative feedback loop is formed because as the performance of a task by a worker increases, the stimulus level of that task decreases. If a worker with a lower threshold reaches a task then the worker with the higher threshold may never reach that threshold and thus will never perform the task \cite{beshers2001models}.

The simplicity of the response threshold model makes it a popular choice for division of labour in swarm robotics, however it suffers from a number of problems. A predominant problem is that a small intrinsic variation in the performance or responsiveness of a workers' ability to complete task may be amplified into large differences in task repertoire or the frequency of task performance. 

The response threshold model makes the assumption that all workers are equally likely to encounter each task and that stable equilibrium is reached when the number of workers performing a task matches the stimulus level and when individual workers maintain constant task performance probabilities \cite{page1990self}.

\subsubsection{Integrated Threshold--Information Transfer Model}

Integrated Threshold Information Transfer model can be discerned from it's name. Workers perform a task when the stimulus they encountered equals an internal threshold - the internal threshold will vary according to genetics. The process of discerning a task stimulus is known as information transfer. Information transfer can be perceived randomly in space, directly or via social information transfer  \cite{fewell1999division}. In Integrated Threshold-Information Transfer, both the integrated threshold can be varied as well as the method of transferring information.

Fewell et al  use information transfer models to predict swarm level response patterns to graded changes in stimulus levels for the tasks. The model predicted that normally distributed patterns of task thresholds would induce a graded response - independently of how the individuals received information about the task \cite{fewell1999division}.

%NOT VERY GOOD BUT FUCK IT!

\subsubsection{Self Reinforcement Models}

Task success is directly proportional of the probability of doing the task again. Self reinforcement models answer the question of whether division of labour be generated as a result of experience \cite{lerman2005review}. If a task was not performed successfully or their was the lack of opportunity then the probability of ever performing that task reduces which leads to the creation of task specialists. 

Foraging specialization can develop equal food location and quantities \cite{deneubourg1987self}.
The study suggests that both self-reinforcement and worker age variation are to account for temporal polyethism. 
%also all needs to be reorganized and rephrased%

Plowright and Plowright \cite{plowright1988elitism} use self-reinforcement to generate elitism. Given an initial random population of encountering tasks, the threshold was incremented when tasks were performed. The result was a bi-modally distributed frequency of performing tasks where agents either became specialists or became entirely inactive.

Theraulaz \cite{theraulaz1998response} has the concept of learning and forgetting. Learning is when there is a reduction in response threshold when a worker performs a task. And forgetting is an increase in response threshold when a worker performs a task. All individuals begin with equal thresholds. Evidence from the model indicated that workers adequately adjusted activity levels according to the task they ended up specializing in. %rephrase & rework%
%this is what happens in my own things!!!!!! NBNBNBNBNBNB TO DO - ANALYSIS
%find citation

\subsubsection{Foraging for Work}
Foraging for Work (FFW) has two main parts:
\begin{enumerate}
	\item Workers repeat the same task when possible.
	\item Workers actively seek work when they have no task.
\end{enumerate}

%This forms the basic model of foraging and also is used in MY honey bee algorithm.

Foraging for work makes the assumptions that:
\begin{itemize}
	\item Workers are intrinsically identical and thus task performance of workers is dependent on opportunity, rather than intrinsic task preferences. However, it has been shown that in true insect colonies, there is intrinsic variation in each worker's response to the environment as not all workers will respond equally. 
	\item Tasks are radially spatially localized within the nest. That means the tasks further away are performed by older workers and the younger workers will perform the tasks that are nearer.
\end{itemize}

Foraging for work shows that temporal polyethism doesn't require age-related difference in the mechanism of task choice and can simply stem from the older workers proximity to the nest which is controversial as it sets the base expectation of what level of task organization might occur within a social group in absence of selection efforts or intrinsic mechanism of worker task performance.

\subsubsection{Foraging for Work versus Threshold Models} %not sure if this is even necessary
The exist similarities between foraging for work and threshold models. Patterns of division of labour generated from generated rules and 
- Random variation exists in task encounter/performance threshold

In foraging for work, spatial organization generates temporal polytheism. 
With threshold models, lazy workers are generated by the threshold variation. 

Foraging for work can be seen as a special case of the threshold model where all workers have the same threshold. %confirm - sure this is rubbish I'm sputing

\subsubsection{Social Inhibition Models}

The sheer presence of older foraging bees affects behavioural development as a proportion of bees becoming foragers is indirectly related to the number of older bees present in the colony \citation{huang1992honeybee} which motivates the activator-inhibitor model.

Activator-Inhibitor model is driven by 2 hormones:
\begin{itemize}
	\item The activator is the juvenile hormone which motivates the workers in the hive to become foragers.
	\item The inhibitor hormone that is transferred from the foragers to the younger workers suppresses the bees development into foragers. If foragers are lost in an accident then more hive workers will mature to foragers due to the decrease of the inhibitor hormone.
\end{itemize}

The mathematical version of the social inhibition model represents the workers physiological state by a single variable $x$ that changes daily in response to the social environment \cite{beshers2001social}. The model defines the trajectories for behavioral development that are intrinsically determined and responsive to social environment. Task performance is correlated with age. 

The Eusocial wasp shows similar temporal polytheism:
\begin{itemize}
	\item Each worker has two pools of chemical inhibitor. One pool affects own behavioural state the other is transferred to the workers in encounters. 
	\item The effect of inhibitors on a workers state is the ratio of own activator to the other workers inhibitor.
\end{itemize}

Both reach a dynamically stable allocation of workers to different tasks. Social inhibition provides mechanism of changing worker thresholds as they age. Social inhibition allow colony to flexibly response to changing conditions.

\subsubsection{Network Models of Task Allocation}
In this particular network allocation models a worker performs one of four tasks, where for each task they are either active or inactive. This results in each worker having 8 states. Workers having the same states belong to the same task group.

All worker interactions are bias towards transferring information with workers that belong to the same task group \cite{gordon1992parallel}.

Worker behaviour in each iteration is determined by a linear combination of interactions with a threshold value. The system moves to a balance of active and inactive workers. 

Pascala \cite{pacala1996effects} developed a differential equation to investigate the effects of social group size on task allocation. Information was received directly from the environment, through success or failure of task performance and random encounters with other group members.

Pascala's research showed that large networks (ie a large number of agents) track environmental changes more efficiently as there is a higher rate of information flow but interaction increases substantially causing interference. Thus as colony size increases, the overhead from interactions becomes faster than the information collection rate from the environment. The two components can be kept in balance by regulating the frequency of interactions among workers \cite{pacala1996effects} %look at this citation

The key similarity between network models and foraging for work models is that despite the fact that goals differ, they both share the view that division of labor can be generated by changes in local information encountered by an individual worker. Local information is affected by availability of performance of other tasks, resulting in workers switching between task spaces. Network models are more accurate than the linear model of foraging for work, but network model lacks self organizational properties of foraging for work models.

\subsubsection{Summary} 
Existing models of division of labour are more exploratory but reveal important general principles, however few models have been tested and proven.
%need more methinks

\section{Challenges}
%Need to bulk up
Sahin et al. suggest a number of challenges faced by swarm robotics \cite{csahin2008special}. These challenges are discussed and expanded upon below: 

\begin{itemize}

\item \textbf{Emergent Algorithm Design} - As the field stands, there are no real way to actually design individual behaviour in order to guarantee a specific collective emergence. There exist few approaches to design the simplistic behaviour of an individual robot in order to achieve the desired emergent collective behaviour. Hamman et al. attempts to devise a mathematical model to assist in modelling swarm behaviour and communication\cite{hamann2008framework} to help bridge the local behaviour to global behaviour and another modelling technique, but the techniques are limited to specific sensory or actuation abilities. 

\item \textbf{Experimentation} - In order to properly study swarm robotics, one would require infrastructure for real robotic research - from robot hardware, to monitoring software or simply even security. The need for real robots can be alleviated by use of simulation environments. A number of simulators have been developed in order to enable easier experimentation at different levels of accuracy. Some are only 2D grid-world models while others attempt to mimic real life as accurately as possible. There could be a whole field of study relating to whether these simulators are accurate enough to model upon.

\item \textbf{Analysis and Modelling}: Swarm robotics systems are stochastic non-linear systems and as a result parameter optimisation and verification are very difficult. difficult. Both micro- and macro-models for swarm robotics have been developed. Swarm robotic probabilistic macro-models are reviewed in\cite{lerman2005review}.

\item \textbf{Robotic systems are challenging in themselves}. Swarm robotics has it's own problems but will also still be weighed down by the challenges faced by traditional robotics. Challenges such as the sheer variety of very different fields required to design and program a robot intelligently from physics, programming, artificial intelligence, mechanics.
\end{itemize}


The study of the process of how to achieve reliable real-world swarm systems and how to address the above challenges, is known as swarm engineering \cite{brambilla2013swarm}. %TODO: Cite some real world systems. 

\section{Summary}
\label{sec:first:summary}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%