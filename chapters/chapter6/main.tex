%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Results}
\label{chap:results}

In order to evaluate the the algorithms, the analysis of the performance measures from the experiments were organised around three major characteristics of swarm robotics algorithms, namely flexibility, robustness and scalability. Section~\ref{results:efficiency} addresses general foraging efficiency, while flexibility of the algorithms over different environmental types and configurations is analysed in Section~\ref{results:flexibility}. Section~\ref{results:scalability} evaluates of scalability of each algorithm and robustness is analysed in Section~\ref{results:robustness}. Section~\ref{results:summary} summarizes the findings of the analysis.

\section{Foraging Efficiency}
\label{results:efficiency}

Determining the most efficient algorithm is not the main focus of this study. If the study was focused on finding the most efficient algorithm for each environment, then the parameters (such as $\tau$), for each of the algorithms, would need to be optimized for each environment. This study focuses on the behaviours of each algorithm, and how efficiency of each algorithm is sensitive to environmental and swarm parameters. Thus, it is important to note that the analysis of the foraging efficiency of each environment, looks at experiments with all swarm and environmental parameters, and aims to understand the overall trends of efficiency.

Table~\ref{summarytable} shows the sum of the wins and losses per algorithm against all other algorithms. Desert ant foraging performed better than na\"ive foraging. The honey bee algorithm out-performed the na\"ive foraging algorithm and desert ant algorithm. The following chapters address each of the swarm robotic properties of each algorithm, and explain why the performance of the algorithms is as discussed.


\begin{table}[]
\centering
\caption{Pairwise one-tailed Mann Whitney U wins and losses of $E_p$, for each algorithm, over all environments, parameter value choices }
\label{summarytable}
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{Algorithms} & \textbf{Wins} & \textbf{Losses} \\ \midrule
Naive               & 1168          & 59042           \\
Desert Ant          & 42120         & 14557           \\
Honey Bee           & 45490         & 15179           \\ \bottomrule
\end{tabular}
\end{table}

\section{Flexibility}
\label{results:flexibility}

This section discusses each of the swarm algorithm's flexibility. Section~\ref{results:prioritizeditemratio} discusses flexibility of each algorithm, in terms of the prioritized item ratio of the environment, $F_r$, , as defined Chapter~\ref{setup:flexibility:prioritizeditemratio}.  Section~\ref{results:flexibility:environmentdistribution} discusses the flexibility of each algorithm, in terms of environment distribution types, $F_{ED}$, as defined in Chapter~\ref{setup:flexibility:environmentdistributions}.

\subsection{Flexibility in terms of prioritized item ratio}
\label{results:prioritizeditemratio}

% Please add the following required packages to your document preamble:
% \usepackage{booktabs}
\begin{table}[]
\centering
\caption{Flexibility in terms of prioritized item ratio, $F_r$, and flexibility in terms of environment distribution, $F_{ED}$, for each algorithm}
\label{table:flexibility}
\begin{tabular}{@{}llll@{}}
\toprule
\textbf{}         & Na\"ive         & Desert Ant        & Honey Bee         \\ \midrule
\textbf{$F_r$}    & 1.18580054603 & 3.12400224646     & 0.827991739287    \\ \midrule
\textbf{$F_{ED}$} & 1.11160672365 & 0.507371308759 & 0.458295680454 
\end{tabular}
\end{table}

According to Table~\ref{table:flexibility}, the Honey-bee algorithm is the most flexible, in terms of environment type ratio, $F_r$, out of the the algorithms examined, followed by the Na\"ive algorithm and lastly the Desert Ant algorithm. 

Figure~\ref{fig:specializationratioovertime} suggests that Honey-bee algorithm's flexibility over environment type ratio, $F_r$, can be attributed the Honey-bee algorithm's ability to adapt the specialization ratio, $\tau$, via the division of labour mechanism described in Section~\ref{natureinspired:divisionoflabour}, to more efficiently forage an environment of a given environment item ratio, $r$. Figure~\ref{fig:specializationratioovertime} shows the specialization ratio, $\tau$, for the honey bee algorithm. In Figure~\ref{fig:specializationratioovertime}, the initial swarm specialization ratio, $\tau$, is configured set $\tau=0$, in an environment which only mostly prioritized items ($r=0.75$). After no honey bee scouts can find any non-prioritized items, the scouts all switch to foraging prioritized items, such that $\tau$ goes from 0 to 1 in 200 iterations. Specialization ratio, $\tau$, steadily declines throughout the experiment from 1 till 0.73 showing that the Honey-bee algorithm eventually adapts the specialization ratio, $\tau$, to effectively forage the given environment ratio. 

Despite the Desert Ant algorithm outperforming the Na\"ive algorithm in efficiency, shown in Section~\ref{results:efficiency}, the Na\"ive algorithm is more flexible, according to Table~\ref{table:flexibility}. Rationally, the Na\"ive algorithm does not perform well on any environment, it doesn't necessarily make a difference what specialization ratio the algorithm is run on, as it will always be equally bad. The performance measure $F_r$ is a measure of how performance chances between different types of specialization ratios. An algorithm that does not benefit from any values of $r$ will be seen as more flexible by the performance measure $F_r$, as efficiency is eliminated from $F_r$.

\begin{figure}[!htb]
\centering
\resizebox{\textwidth}{!}{\input{chapters/chapter6/graphs/robustness/specializationratioovertime.tex}}
\caption{Specialization Ratio, $\tau$, of the honey bee algorithm, over time, when $\tau=0$ and $r=0.75$}
\label{fig:specializationratioovertime}
\end{figure}


\subsection{Flexibility in terms of Environment Distributions}
\label{results:flexibility:environmentdistribution}

% Refer back to tables
An examination of $F_{ED}$ in Table~\ref{table:flexibility} indicates that the Honey Bee algorithm is the most flexible, followed by the Desert Ant, with the Na\"ive Algorithm being the least flexible.

Each environment distribution was chosen for experimentation in order to test whether each algorithm has the ability to overcome specific challenges and complexities that result from the environment distributions, as described in Section~\ref{experimentenvironments}.

Since the Honeybee algorithm is more flexible than the Na\"ive algorithm, the following properties will emerge from swarm's running the Honeybee algorithm, as opposed to the Na\"ive algorithm:
\begin{itemize}
\item A better ability to forage obstacles (the non-prioritized items) to reach the prioritized items.
\item A better ability to return to areas of high quality
\end{itemize}
 
The Honeybee algorithm allows robots to switch specialization (described in Section~\ref{somewhere}), which suggests that the Honeybee algorithm will have the ability to adapt a swarms swarm specialization ratio $\tau$, so that more robots forage blocking non-prioritized items can form obstacles before reaching prioritized items. Consider the environment shown in Figure~\ref{fig:gaussianhighdensityenv} where the concentration of prioritized items are blocked by non-prioritized items. The white cells are empty, the dark cells are the non-prioritized items and the shaded cells are the prioritized items. The environment in Figure~\ref{fig:gaussianhighdensityenv} has the following properties:

\begin{itemize}
\item Gaussian environment item distribution.
\item A low environmental item ratio of $r=0.2$.
\item A high density of items $p=90$.
\item $S=100$
\end{itemize}

\begin{figure}[!htb]
\centering
\includegraphics[width=0.75\textwidth]{chapters/chapter6/figures/flexibility-gaussian-obj90-ratio.PNG}
\caption{Gaussian environment distributed environment, $r=0.2$, $p=90$, $s=100$}
\label{fig:gaussianhighdensityenv}
\end{figure}

\begin{figure}[!htb]
\centering
\small
\resizebox{\textwidth}{!}{\input{chapters/chapter6/graphs/flexibility/flexibility-ED-gaussian-honeybee.tex}}
\caption{Efficiency of prioritized item foraging $E_P$, Efficiency of non-prioritized item foraging $E_{NP}$, Specialization ratio $\tau$ over time, for Honeybee Algorithm on a Gaussian Environment}
\label{fig:gaussianhighdensityperformancehoneybee}
\end{figure}

\begin{figure}[!htb]
\centering
\small
\resizebox{\textwidth}{!}{\input{chapters/chapter6/graphs/flexibility/flexibility-ED-gaussian-naive.tex}}
\caption{Efficiency of prioritized item foraging $E_P$, Efficiency of non-prioritized item foraging $E_{NP}$, Specialization ratio $\tau$ over time, for Nai\"ve algorithm on a Gaussian Environment}
\label{fig:gaussianhighdensityperformancenaive}
\end{figure}

\begin{figure}[!htb]
\centering
\small
\resizebox{\textwidth}{!}{\input{chapters/chapter6/graphs/flexibility/flexibility-ED-uniform-honeybee.tex}}
\caption{Efficiency of prioritized item foraging $E_P$, Efficiency of non-prioritized item foraging $E_{NP}$, Specialization ratio $\tau$ over time, for Honeybee algorithm on a Uniform Environment}
\label{fig:uniformhighdensityperformancehoneybee}
\end{figure}


Consider the experiment where the initial specialization ratio, $\tau$, set to mostly forage prioritized items ($\tau=0.8$) with $c=50$ on the described environment. 

Figure~\ref{fig:gaussianhighdensityperformancehoneybee} shows the efficiency of foraging prioritized items $E_p$ and the efficiency of foraging non-prioritized items $E_p$, as well as the specialization ratio, $\tau$, for the honey bee algorithm, for each 200 time steps, on the environment described above. The specialization ratio $\tau$ starts at 0.8 and then very quickly decreases to near 0 and soon after, the $E_{NP}$ picks up very quickly (since more robots are foraging non-prioritized items). After a couple 100 time steps, $E_{P}$ and $\tau$ increase dramatically, since the non-prioritized items have been cleared and the concentration of prioritized items in the centre have been reached. 
Figure~\ref{fig:gaussianhighdensityperformancehoneybee} shows the efficiency of foraging prioritized items $E_p$ and the efficiency of foraging non-prioritized items $E_p$, as well as the specialization ratio, $\tau$, for the Na\"ive algorithm, for each 200 time steps, on the environment described above. The swarm specialization, $\tau$, stays constant. As a result, the increase of $E_{NP}$ is slow because few robots can forage the non-prioritized items which are forming obstacles for the prioritized items. As a result on the swarm's inability to clear the non-prioritized items $E_P$ also remains low since foraging the prioritized items is slowed by obstacles. The graph for the Desert Ant algorithm is similar, except final efficiency is higher than for the Na\"ive algorithm.

The final $E_P$ for the Honeybee algorithm is 0.9, where as the final $E_P$ for the Na\"ive algorithm is 0.3. This behaviour of the Honeybee algorithm compared to the Na\"ive algorithm, motivates the notion that the Honeybee algorithm's ability to adapt the swarm specialization ratio, means in an swarm that can forage non-prioritized items that are obstacles to reaching the prioritized items. The ability to forage non-prioritized items that are forming obstacles results in an algorithm that can perform well on a variety of environment distributions and the Honey-bee algorithm is thus more flexible.

\section{Scalability}
\label{results:scalability}

This section discusses each of the algorithm's scalability. Section~\ref{results:swarmscalability} discusses scalability of each algorithm, in terms of swarm density, $SS$, as defined Chapter~\ref{swarmsizescalability} while Section~\ref{results:problemscalability} discusses the scalability of each algorithm, in terms of the size of the problem, $PS$, as defined in Chapter~\ref{setup:problemscalability}.

\subsection{Swarm scalability}
\label{results:swarmscalability}
According to Table~\ref{table:swarmscalability} and Figure~\ref{fig:swarmscalability}, which illustrate results of the swarm scalability performance measure $SS$, the Na\"ive algorithm is the most scalable in terms of swarm size. The Desert ant and Honey bee algorithms show similar scalability. The Honey bee algorithm at lower densities appears to be more scalable than the Desert Ant algorithm, but at the higher densities, $SS$ of the Desert Ant algorithm over takes the Honey bee algorithm.

Figure~\ref{fig:swarmscalability} also plots ideal linear scalability, where the increase in swarm size is directly proportional to the increase in efficiency. The performance of all algorithms is sub-linear. In Section~\ref{swarmsizescalability}, increased inter-robot interference is highlighted as a major factor impacting swarm scalability and thus one can conclude that the reason for sub-linear performance is because all algorithms suffer from increased inter-robot interference as swarm size increases

The Na\"ive algorithm, being the most simple foraging algorithm, has no mechanism to enable the swarm to exploit high quality sites of prioritized items and can only locate items by randomly exploring the environment. Both the Desert ant algorithm and the Hony bee algorithm have mechanisms to exploit high quality areas: The Desert ant algorithm uses site fidelity and the Honey bee algorithm uses recruitment to exploit high quality sites. 

To understand why the exploitative nature of the Desert ant and Honey bee algorithm results in the algorithm's being less scalable than the Na\"ive algorithm, consider the following scenario:

There exists a single high quality site in an environment. By use of site-fidelity and recruitment, the Desert Ant and Honey bee algorithms can exploit that area. In exploiting that high quality site, the path between the sink and the high-quality site becomes more congested. The increased congestion will cause more inter-robot interference, but due to the focused efforts, the exploitation will still improve performance overall. However, if swarm density increases, the congestion on the route between the high quality site and the sink, will increase, hindering the overall efficiency. It follows that the Desert ant algorithm and Honey bee algorithm are less scalable in terms of swarm sie, then the Na\"ive algorithm, due to the congestion caused by exploitation.

The Honey bee algorithm performed slightly better than the Desert ant algorithm, according to Table~\ref{table:swarmscalability}, for everything except the extremely high values of $c$. The recruitment mechanism used by the Honey bee algorithm is a more extreme form of exploitation than site fidelity used by the Desert ant algorithm, since scouts recruit groups of robots to forage single areas. On the other hande, when using site fidelity, the high quality site is only foraged by the robot that found it. Considering that the recruitment mechanism is more exploitative than the site fidelity mechanism, one would expect the Honey bee algorithm to be much less scalable than the Desert ant algorithm, but that is not evidential in Table~\ref{table:swarmscalability}. 

The Honey bee algorithm has an extra mechanism that can influence the number of robots active in an environment, namely, the division of labour mechanism, described in Section~\ref{honeybeeforaging}. The division of labour mechanism will cause an active forager robot to return to the sink if that robot can't find an item for a maximum amount of time. The inactive forager robot waits at the sink, until the inactive forager robot is recruited by a scout robot. Section~\ref{background:divisionoflabour:robotswarm} discussed that a mechanism of division of labour, which can adjust the number of robots actively foraging to an appropriate amount, will result in decreased levels of inter-robot interference, thus increasing swarm scalability.

In order to determine whether the slight improvement in scalability on the Honey bee algorithm over the Desert ant algorithm can be attributed to the waiting time, the average time spent by any robot in the waiting state for the Honey bee algorithm is plotted for different values of $c$ in Figure~\ref{doesnotexistyet}. It is clear from Figure~\ref{doesnotexistyet} that the robots spend a significant portion of time in the waiting state. However the time spent in the waiting state, decreases as swarm density increases. This result is counter-intuitive, since, if a division of labour mechanism which attempts to regulate active foragers is functioning adequately, then robots would spend more time in the waiting state on average when the swarm size is greater, due to the increased inter-robot interference. 


\begin{table}[]
\centering
\caption{Swarm scalability, $SS$, for each swarm density, $c$, for each algorithm.}
\label{table:swarmscalability}
\begin{tabular}{@{}lllllll@{}}
\toprule
\textbf{$c$}            & \textbf{0.1} & \textbf{0.3}         & \textbf{0.5}         & \textbf{0.7}         & \textbf{1}           \\ \midrule
\textbf{Na\"ive}    & 1   & 2.148309055 & 2.95067493  & 3.567754813 & 4.25529855  \\
\textbf{Desert Ant} & 1   & 1.972768821 & 2.604500744 & 3.05833543  & 3.555516648 \\
\textbf{Honey Bee}  & 1   & 2.067364168 & 2.706034502 & 3.119174449 & 3.532352867 \\ \bottomrule
\end{tabular}
\end{table}

\begin{figure}[!htb]
\centering
\small
\resizebox{\textwidth}{!}{\input{chapters/chapter6/graphs/scalability/swarmscalability.tex}}
\caption{Swarm Scalability, $SS$, for each swarm density $c$, for each algorithm, as well as linear scalability as swarm density increases.}
\label{fig:swarmscalability}
\end{figure}

\begin{figure}[!htb]
\centering
\small
\resizebox{\textwidth}{!}{\input{chapters/chapter6/graphs/scalability/swarm-scalability-waitingtime.tex}}
\caption{Average Time in Waiting State, $t_{wait}$, for each swarm density $c$, for the Honey bee algorithm}
\label{fig:swarmscalabilitywaitingtime}
\end{figure}


\subsection{Problem scalability}
\label{results:problemscalability}

Figure~\ref{fig:problemscalability} plots the problem scalability performance measure $PS$ (described in Section~\ref{setup:problemscalability}) for each algorithm, with values given in Table~\ref{table:problemscalability}. The plot of Expected scalability runs on the assumption that efficiency would degrade proportionally to the total number of items that can be foraged, and plots the expected value for $PS$ accordingly. All algorithm's outperform the expected scalability and thus problem scalability for all algorithms is super-linear. % Need to motivate

According to Figure~\ref{fig:problemscalability}, the Honeybee algorithm is the most scalable in terms of $PS$, followed by the Na\"ive algorithm, with the Desert ant algorithm having the worst scalability. %WHY CAN I SAY THAT?

As stated in Section~\ref{setup:problemscalability}, the inability for an algorithm to scale with regards to the size of the problem, is due to an ineffectiveness of handling the increased environmental interference that occurs in problems of greater complexity.

The Na\"ive algorithm is more scalable than the Desert Ant algorithm. The Desert Ant algorithm is the same as the Na\"ive algorithm, except that the Desert Ant algorithm employs site fidelity, described in Section~\ref{desertantforaging}, to enable a robot to return to a previously foraged site. Rationally, the site fidelity mechanism, directly or indirectly, must be the reason for the decreased scalability of the Desert Ant algorithm. To motivate why the site fidelity mechanism is negatively influencing scalability, consider the following scenario: A robot employs a random walk through a complex environment, as shown in red in Figure~\ref{fig:desertantsitefidelity}. The random walk leads the robot to a source of prioritized items. The robot stores the PI vector, shown in blue on the figure, which is needed to return back to the site after offloading the current item at the sink. The PI vector is a single vector with heading and distance. The next time the desert ant wants to return to the previous site, the robot will still need to perform the same obstacle avoidance in order to navigate around the obstacles to return to the previously foraged vector. As is evident on the Figure, there may exist an easier to reach site for prioritized items, but the desert ant will continue to attempt to forage the hard to locate source of items. On the other hand the Na\"ive algorithm, due to the fact it can't exploit previously location areas using site fidelity, explores more and is more likely to randomly find the prioritized resource site that is nearer the sink (indicated by the green path). The time spent on relocating hard to access sites, in more complex environments, can slow the Desert ant algorithm down.

\begin{figure}[!htb]
\centering
\includegraphics[width=0.75\textwidth]{chapters/chapter6/figures/problem-scalability-desertant.png}
\caption{Illustration of the inefficiencies of Desert Ant algorithm's site fidelity in dense environments. Solid areas are non-prioritized items, white areas are free cells and shaded areas are prioritized items. The red path is a hypothetical random walk performed by a robot, the blue path is the PI vector for the red random walk, and the green path is an alternative random walk.}
\label{fig:desertantsitefidelity}
\end{figure}

The Honeybee algorithm also uses site-fidelity, and on top of that, communicates those sites to others. Despite the use of similar site-fidelity mechanism to the Desert Ant algorithm, the Honey bee algorithm is the most scalable. The reason why the site-fidelity of the Honey bee algorithm does not impact the scalability, can be attributed the ability of the Honey bee algorithm to adapt the swarm specialization ratio, $\tau$, to focus on foraging dense areas of obstacles, rather than having to expensively navigate around the obstacles. The ability of the Honey-bee algorithm to concentrate on clearing obstacles in highly dense environments, will increase overall ease of access to the high quality sites, as was discussed in Section~\ref{results:flexibility:environmentdistribution}, and thus improving efficiency of the Honeybee algorithm in highly dense environments. As a result, the Honeybee algorithm is the most scalable in terms of the problem complexity.


\begin{table}[]
\centering
\caption{Problem Scalability, $PS$, for each environment density $p$, for each algorithm}
\label{table:problemscalability}
\begin{tabular}{@{}llllll@{}}
\toprule
\textbf{$p$}                  & \textbf{0.05} & \textbf{0.2        } & \textbf{0.5}         & \textbf{0.7}         & \textbf{0.9}         \\ \midrule
\textbf{Desert Ant}           & 1    & 0.487816741 & 0.231581619 & 0.181686679 & 0.167953071 \\
\textbf{Honey Bee}            & 1    & 0.602283728 & 0.283264856 & 0.216749784 & 0.195686487 \\
\textbf{Na\"ive}              & 1    & 0.501722909 & 0.256758663 & 0.195206738 & 0.174522486 \\
\textbf{Expected} & 1    & 0.25        & 0.1         & 0.071428571 & 0.055555556 \\ \bottomrule
\end{tabular}
\end{table}

\begin{figure}[!htb]
\centering
\resizebox{\textwidth}{!}{\input{chapters/chapter6/graphs/scalability/problemscalability.tex}}
\caption{Problem Scalability, $PS$, for each environment density $p$, for each algorithm}
\label{fig:problemscalability}
\end{figure}

\section{Robustness}
\label{results:robustness}
% describe fault tolerance, and provide rational arguments as to why it would be more or less 
This study does not perform an empirical robustness study to specifically address how fault tolerant each algorithm is. Instead, rational arguments are provided below, to discuss the robustness of each algorithm. Evidence is provided to support the arguments. As discussed in Section~\ref{robustness}, swarm robotics achieves robustness by having the properties of redundancy, multiplicity of sensing and decentralized coordination. This section aims to provide rational arguments supported by empirical evidence to discuss each  algorithm's capability for the properties of robustness. Section~\ref{results:redundancy} discusses robustness in terms of redundancy of each algorithm, and Section~\ref{results:decentralizedcoordination} discusses robustness in terms of decentralized coordination.

\subsection{Redundancy}
\label{results:redundancy}
For each of our algorithms, a swarm is configured with an initial swarm specialization ratio, as discussed in Section~\ref{chap:experiment} to enable a portion of robots to forage prioritized items and the another portion to forage non-prioritized items. 

If a portion of robots in a swarm malfunction or are destroyed, then the swarm specialization ratio could be affected. As shown in Section~\ref{results:flexibility}, the foraging efficiency of the na\"ive and desert ant algorithms are effected by the initial swarm specialization ratio $\tau$. Thus, if the swarm specialization ratio is unexpectedly changed, during the swarm experiment, one would expect changes to foraging efficiency that would persist for the life-time of the swarm. In particular, consider the following extreme scenarios: 

Suppose all the robots which were foraging for prioritized items (for some $\tau > 0$) are destroyed or malfunction (thus $\tau=0$). Foraging efficiency would drop to 0 since there do not exist any robots to forage prioritized items. Similarly, consider an environment where all prioritized items are blocked by non-prioritized items, and $\tau < 1$ . If all non-prioritized robots suffer a malfunction or are destroyed, then $\tau=1$ and there exist no robots to forage non-prioritized items then foraging efficiency would become zero. 

Because the the robots running the na\"ive algorithm and desert ant algorithms are heterogenous, because they each forage a specified item type, there is less redundancy than an algorithm where robots can forage both types of items or switch to foraging different types of items.

As shown in Section~\ref{results:flexibility}, the Honey-bee algorithm does not experience large changes to efficiency, when $\tau$ is varied. The Honey-bee algorithm would not suffer the same problem, due to the division of labour mechanism, described in Section~\ref{honeybeeforaging}, which allows each robot to switch which type of item that robot will forage. The honey-bee algorithm adapts the swarm specialization ratio, $\tau$, over time and would, as a result, re-adapt the swarm specialization ratio, in order to recover from the destruction of individuals foraging specific item types. Figure~\ref{fig:specializationratioovertime} provides evidence that the honey bee algorithm allows the swarm to adapt the swarm specialization ratio. In Figure~\ref{fig:specializationratioovertime}, the initial swarm specialization ratio, $\tau$, is configured as $\tau=0$, in an environment which only mostly prioritized items ($r=0.75$). After no honey bee scouts can find any non-prioritized items, the scouts all switch to foraging prioritized items, such that $\tau$ goes from 0 to 1 in 200 iterations. Specialization ratio, $\tau$, steadily declines throughout the experiment from 1 till 0.73.

The honey-bee algorithm is homogeneous, in that every robot in the swarm has the ability to take on any of the roles required for the algorithm to function (scout, unemployed forager, employed forager), as well as adapt to forage either prioritized and non-prioritized items. Thus the honey-bee algorithm rationally has better redundancy than the desert ant and na\"ive algorithms.

\subsection{Decentralized Co-ordination}
\label{results:decentralizedcoordination}

%Some sort of intro

The desert ant and na\"ive algorithm do not have coordination between any individuals in the swarm. Any co-ordination that emerges is thus entirely decentralized. 

The Honey-bee algorithm uses communication as a coordination mechanism, in order to recruit foragers to areas with a high density of prioritized items, as described in Section~\ref{honeybeeforaging}. If the scout robots experiences a fault in evaluating the quality of a site (for instance, detecting whether a site is of high quality, when it is actually a poor quality site), then foragers will be recruited to forage sites of low quality, incorrectly. Only a few individuals (the scouts), can coordinate the swarm and therefore any faults in the scout robots, can negatively influence effect the efficiency of the entire swarm. Co-ordination mechanisms are therefore, not entirely decentralized.

Table~\ref{averagetimerecruitment} shows the average time steps, per robot, per item foraged, that were spent performing recruitment, for the honey bee algorithm, in each environment distribution, for each environment item type ratio. 

In a uniformly distributed environment, with a low ratio of prioritized items, sites with a high quality do not exist. However, Table~\ref{averagetimerecruitment} shows that each robot spent on average more than a 10th of the total duration of the experiment broadcasting site quality to other robots, where $r$ is between 0 and 0.25. This means that the scouts were recruiting other robots to forage areas that were not of a high quality. The fact that scouts can mislead the swarm to foraging sites with low quality, shows that the honey bee algorithm is less robust.

\begin{table}[]
\centering
\caption{Average time steps, per robot, that were spent performing recruitment, for the honey bee algorithm, in each environment distribution, for each environment item type ratio}
\label{averagetimerecruitment}
\begin{tabular}{@{}lllll@{}}
\toprule
$r$            & \textbf{clustered} & \textbf{gaussian} & \textbf{uniform} & \textbf{vein} \\ \midrule
\textbf{0}        & 0.163853094        & 0.162636914       & 0.159305395      & 0.163353443   \\
\textbf{0.2}      & 0.119486333        & 0.152139262       & 0.11962912       & 0.160737113   \\
\textbf{0.25}     & 0.126752914        & 0.144484389       & 0.127568794      & 0.158813789   \\
\textbf{0.333333} & 0.140492087        & 0.135243974       & 0.139460537      & 0.151803907   \\
\textbf{0.5}      & 0.161644793        & 0.15738657        & 0.16335568       & 0.168543223   \\
\textbf{0.666667} & 0.181659692        & 0.174940591       & 0.183477822      & 0.151701447   \\
\textbf{0.75}     & 0.179285021        & 0.177420259       & 0.183721153      & 0.171862739   \\
\textbf{0.8}      & 0.182807781        & 0.182650316       & 0.186144899      & 0.190969001   \\
\textbf{1}        & 0.167397088        & 0.172990294       & 0.163048904      & 0.219223401   \\ \bottomrule
\end{tabular}
\end{table}

\section{Summary}
\label{results:summary}

This chapter presented the results of the experiments and performed analysis of each of the major properties of swarm robotics. The results were discussed around three axes of: efficiency, flexibility, robustness and scalability. 

Section~\ref{results:efficiency} presents an overview of foraging efficiency of each algorithm. The results showed that the Honey bee algorithm performed the best over all environments and initial swarm configurations, while the desert ant performed next best and lastly followed by the Na\"ive algorithm.

Flexibility was discussed in terms of flexibility over environments prioritized item ratio, $F_r$, and flexibility over environment distribution type, $F_{ED}$. 

Section~\ref{results:prioritizeditemratio} concluded that the Honey-bee algorithm is the most flexible in terms of prioritized item ratio. It was shown the Honey-bee algorithm's flexibility is due to the Honey-bee algorithm's ability to adapt the specialization ratio $\tau$, via the division of labour mechanism in Section~\ref{something}. The division of labour mechanism allowed the Honey bee algorithm to more efficiently forage an environment for a given environment item ratio. The Na\"ive algorithm is more flexible than the Desert ant algorithm, in terms of environment item distribution. The Na\"ive algorithm's perceived flexibility is attributed to the fact that the Na\"ive algorithm suffers far lower efficiency across all environment item ratios, suggesting that it appears flexible since it performs equally bad across all values of $r$, unable to benefit from any configuration in the environment. 

Section~\ref{results:flexibility:environmentdistribution} concluded that the Honey bee algorithm is the most flexible, followed by the Desert Ant algorithm and lastly the Na\"ive algorithm. The Honey bee algorithm was determined to be more flexible, due to it's ability to adapt the specialization ratio to better suit the types of items that are reachable at any point, by the swarm. The adaptation of specialization ratio allowed the Honey bee swarm to focus on foraging obstacles when only non-prioritized items were reachable, and then adjust the ratio to focus on foraging prioritized items when prioritized items were reachable. The Desert Ant and Na\"ive algorithms, without the ability to adjust to changing ratio of the reachable objects, cannot assign more resources to forage a high ratio of reachable non-prioritized resources, and are thus less flexible than the Honey bee algorithm.
  The Na\"ive algorithm's perceived flexibility over environment distribution, is attributed to the same reasons as determined by Section~\ref{results:prioritizeditemratio}. 
  
Section~\ref{results:scalability} evaluated scalability in terms of swarm scalability, $SS$ and $PS$. Section~\ref{results:swarmscalability} determined that the scalability of all algorithms was sublinear. More specifically, the Na\"ive algorithm was the most scalable in terms of swarm density, followed by the Desert Ant algorithm and Honey-bee algorithm which exhibited similar scalability. The Desert Ant's poor performance, compared to the Na\"ive algorithm poor performance is attributed the Desert Ant's use of site fidelity. A rational argument was presented to argue the Desert Ant algorithm's site fidelity increases inter-robot interference, resulting in poor performance when the swarm density is high. The Honey-bee is shown to be slightly more scalable than the Desert ant algorithm, due to the Honey-bee algorithms attempt to regulate the number of active foragers by division of labour. The difference in swarm scalability between the Desert ant algorithm and Honey-bee algorithm is very small, suggesting that the regulation of active foragers was not functioning very well. The Honey-bee algorithm's ability to regulate the number of active foragers as swarm densities increase, was shown to be ineffective. 

Section~\ref{results:problemscalability} determined that the Honey-bee algorithm is the most scalable in terms of problem scalability, followed by the Na\"ive algorithm, and lastly the Desert ant algorithm. The discussion showed that the Desert Ant's performed comparatively worse than the Na\"ive algorithm in terms of problem scalability, due to the Desert Ant algorithm's use of site fidelity to exploit good search areas. The section determined the the Na\"ive algorithm's ability to explore more than the Desert Ant algorithm, resulted in better problem scalability. Despite the use of the Honey-bee algorithm's site fidelity, the Honey-bee algorithm was the most scalable. The problem scalability of the Honey-bee algorithm can be attributed to the ability of the Honey-bee algorithm to clear obstacles, which results in lower inter-robot and environmental interference, increasing the problem scalability.

Section~\ref{results:robustness} addressed robustness of each of the algorithms, in terms of redundancy and Decentralized co-ordination. Section \ref{results:redundancy} rationally showed that the Honey-bee algorithm is the most redundant, since the robots can switch specialization. The Desert ant algorithm and Na\"ive algorithm are less redundant, since each robot can only a single item type.

Section~\ref{results:decentralizedcoordination} determined that the Desert ant and Na\"ive algorithm are the most robust in terms of decentralized coordination, since neither algorithm employ any communication mechanism between robots of the swarm. The honey bee algorithm was determined to be the least robust in terms of decentralized coordination. The Honey bee algorithm 's coordination mechanism, was shown to be sensitive to faults in certain individuals and the failures of the coordination mechanism resulted in a decrease in performance.

%DONT THINK THIS GOES HERE%
Tying the flexibility, scalability, and robustness of each algorithm back to the foraging efficiency: The Honey-bee algorithm exhibited a high level of flexibility, problem scalability, and redundancy, resulting in greater overall efficiency than the Desert Ant algorithm and Na\"ive algorithm. On the other hand, despite the Na\"ive algorithm exhibiting better scalability than the Desert ant algorithm, the Desert ants algorithm's ability too exploit good areas, resulted in greater average performance than the Na\"ive algorithm.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%1%%%%%%%
