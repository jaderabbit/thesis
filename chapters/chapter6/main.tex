%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Results}
\label{chap:results}

The discussion of the results of the experiments is organised around four major characteristics of swarm robotics algorithms, namely efficiency, flexibility, robustness and scalability. Section~\ref{results:efficiency} addresses foraging efficiency, while flexibility of the algorithms over different environment distributions and item type ratios is analysed in Section~\ref{results:flexibility}. Section~\ref{results:scalability} evaluates of scalability of each algorithm and robustness is analysed in Section~\ref{results:robustness}. Section~\ref{results:summary} summarizes the findings of the analysis.

\section{Foraging Efficiency}
\label{results:efficiency}


Despite the fact that determining the most efficient algorithm is not a main focus of this study, this section does a brief comparison of the foraging efficiency, as defined in Section~\ref{setup:foragingefficiency}, of each algorithm. 

This is done by comparing the performance of the three algorithms over all environments and experimental parameters. A wilcoxin test, of a confidence level of 0.05, was applied to each pair of algorithms to determine if a statistically significant difference in performance of a pair of algorithms exists. If a statistically significant difference is indicated, then two one-tailed Mann-Whitney U tests were performed with a confidence level of 0.05, to determine which algorithm was more efficient on a particular experiment. TODO: explain wins and losses somehow

To determine an algorithm's foraging efficiency in comparison to all other algorithms, the wins and losses per each experiment performed for each algorithm, are summed. This statistical analysis approach has been used in \cite{helbig2013performance}.

Table~\ref{summarytable} shows the total wins and losses for each algorithm. The desert ant foraging performed better than the na\"ive algorithm. The honey bee algorithm out-performed both the na\"ive algorithm and the desert ant algorithm. The following sections analyse the swarm robotic properties of each algorithm, and explain why the foraging efficiency of the algorithms is as shown in Table\ref{summarytable}.


\begin{table}[]
\centering
\caption{Pairwise one-tailed Mann Whitney U wins and losses of $E_p$, for each algorithm, over all environments, parameter value choices }
\label{summarytable}
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{Algorithms} & \textbf{Wins} & \textbf{Losses} \\ \midrule
Na\"ive               & 1168          & 59042           \\
Desert ant          & 42120         & 14557           \\
Honey bee           & 45490         & 15179           \\ \bottomrule
\end{tabular}
\end{table}

\section{Flexibility}
\label{results:flexibility}

This section analyses the flexibility of each of the considered algorthms. Section~\ref{results:prioritizeditemratio} analyses flexibility of each algorithm, in terms of the prioritized item ratio of the environment, $F_r$, as defined Section~\ref{setup:flexibility:prioritizeditemratio}. Section~\ref{results:flexibility:environmentdistribution} discusses the flexibility of each algorithm, in terms of environment distribution types, $F_{ED}$, as defined in Section~\ref{setup:flexibility:environmentdistributions}.

\subsection{Flexibility in terms of prioritized item ratio}
\label{results:prioritizeditemratio}

The performance measure $F_r$ is a measure of how performance chances between different types of specialization ratios. An algorithm that does not benefit from any values of $r$ will be seen as more flexible by the performance measure $F_r$, as efficiency is eliminated from $F_r$.

Table~\ref{table:flexibility} shows the flexibility of each foraging algorithm, in terms of environment type ratio, $F_r$. According to Table~\ref{table:flexibility}, the Honey bee algorithm is the most flexible in terms of $F_r$, followed by the Na\"ive algorithm and finally the Desert ant algorithm. 

 
% Please add the following required packages to your document preamble:
% \usepackage{booktabs}
\begin{table}[]
\centering
\caption{Flexibility in terms of prioritized item ratio, $F_r$, and flexibility in terms of environment distribution, $F_{ED}$, for each algorithm}
\label{table:flexibility}
\begin{tabular}{@{}llll@{}}
\toprule
\textbf{}         & Na\"ive         & Desert ant        & Honey bee         \\ \midrule
\textbf{$F_r$}    & 1.18580054603 & 3.12400224646     & 0.827991739287    \\ \midrule
\textbf{$F_{ED}$} & 1.11160672365 & 0.507371308759 & 0.458295680454 
\end{tabular}
\end{table}



Figure~\ref{fig:specializationratioovertime} shows the specialization ratio, $\tau$, over time, for the Honey bee algorithm on a particular environment. The initial swarm specialization ratio, $\tau$, is set to 0, so that no robots are initially set to forage prioritized items. The environment, on the other hand, consists of mostly prioritized items ($r=0.75$). 

An examination of Figure~\ref{fig:specializationratioovertime} shows that $\tau$ increased from 0 to 1 in 200 iterations, which suggests that when no Honey bee scout robots could find any non-prioritized items, the Honey bee scouts switched to looking for prioritized items. After 200 iterations, the specialization ratio, $\tau$, steadily declines throughout the experiment from 1 till 0.73, suggesting that the Honey bee algorithm eventually adapts the specialization ratio, $\tau$, to effectively forage the environment item type ratio $r$ of any given environment.

The above analysis suggests that Honey bee algorithm's flexibility, $F_r$, can be attributed the Honey bee algorithm's ability to adapt the swarm's specialization ratio, $\tau$, via the division of labour mechanism described in Section~\ref{natureinspired:divisionoflabour}, to more efficiently forage an environment of a given environment item ratio, $r$. The Na\"ive algorithm and Desert ant algorithm do not have the ability to adapt $\tau$ and are less flexible than the Honey bee algorithm.

Despite the Desert ant algorithm outperforming the Na\"ive algorithm in efficiency, as shown in Section~\ref{results:efficiency}, the Na\"ive algorithm is more flexible, according to Table~\ref{table:flexibility}. Rationally, since the Na\"ive algorithm does not have high efficiency on any environment, foraging efficiency was not affected very much by any specialization ratio, unable to take advantage of any value for $r$ of $\tau_0$ and thus, will always be equally bad.

%The flexibility of the Desert ant algorithm is the worst out of the considered algorithms. Table~\ref{doesnotexistyet shows that the Desert ant algorithm's performance is very dependant on the value of $\tau_0$.

\begin{figure}[!htb]
\centering
\resizebox{\textwidth}{!}{\input{chapters/chapter6/graphs/robustness/specializationratioovertime.tex}}
\caption{Specialization Ratio, $\tau$, of the Honey bee algorithm, over time, when $\tau=0$ and $r=0.75$}
\label{fig:specializationratioovertime}
\end{figure}


\subsection{Flexibility in terms of Environment Distributions}
\label{results:flexibility:environmentdistribution}

% Refer back to tables
An examination of $F_{ED}$ in Table~\ref{table:flexibility} indicates that the Honey bee algorithm was the most flexible, followed by the Desert ant algorithm. The Na\"ive algorithm was the least flexible.

Each environment distribution was selected to test whether each algorithm has the ability to overcome specific challenges and complexities that result from each environment distributions, which were described in Section~\ref{experimentenvironments}.

As described in Section~\ref{honeybeeforaging}, the Honey bee algorithm allows each robot to switch their item type specialization. Section~\ref{above} showed that the Honey bee algorithm could adapt $\tau$ to adequately forage a specific environment item type ratio $r$. This suggests, that the Honey bee algorithm could also adapt $\tau$ to adapt to localized changes in the environment item type ratio, during the course of foraging. 

Consider the environment shown in Figure~\ref{fig:gaussianhighdensityenv} where the concentration of prioritized items in the environment centre,are blocked by non-prioritized items. The white cells are empty, the dark cells are the non-prioritized items and the shaded cells are the prioritized items. The environment in Figure~\ref{fig:gaussianhighdensityenv} has the following properties:

\begin{itemize}
\item Gaussian environment item distribution.
\item A low environmental item ratio of $r=0.2$.
\item A high density of items $p=90$.
\item $S=100$
\end{itemize}

\begin{figure}[!htb]
\centering
\includegraphics[width=0.75\textwidth]{chapters/chapter6/figures/flexibility-gaussian-obj90-ratio.PNG}
\caption{Gaussian environment, $r=0.2$, $p=90$, $s=100$}
\label{fig:gaussianhighdensityenv}
\end{figure}

\begin{figure}[!htb]
\centering
\small
\resizebox{\textwidth}{!}{\input{chapters/chapter6/graphs/flexibility/flexibility-ED-gaussian-honeybee.tex}}
\caption{Efficiency of prioritized item foraging $E_P$, efficiency of non-prioritized item foraging $E_{NP}$, specialization ratio $\tau$ over time, for the Honey bee algorithm on a Gaussian environment}
\label{fig:gaussianhighdensityperformancehoneybee}
\end{figure}

\begin{figure}[!htb]
\centering
\small
\resizebox{\textwidth}{!}{\input{chapters/chapter6/graphs/flexibility/flexibility-ED-gaussian-naive.tex}}
\caption{Efficiency of prioritized item foraging $E_P$, efficiency of non-prioritized item foraging $E_{NP}$, specialization ratio $\tau$ over time, for the Nai\"ve algorithm on a Gaussian Environment}
\label{fig:gaussianhighdensityperformancenaive}
\end{figure}

\begin{figure}[!htb]
\centering
\small
\resizebox{\textwidth}{!}{\input{chapters/chapter6/graphs/flexibility/flexibility-ED-uniform-honeybee.tex}}
\caption{Efficiency of prioritized item foraging $E_P$, efficiency of non-prioritized item foraging $E_{NP}$, specialization ratio $\tau$ over time, for the Honey bee algorithm on a Uniform environment}
\label{fig:uniformhighdensityperformancehoneybee}
\end{figure}


Consider an experiment with the initial specialization ratio set to mostly forage prioritized items ($\tau=0.8$) where swarm density is set to 0.5, on the Gaussian environment shown in Figure~\ref{fig:gaussianhighdensityenv}. The items nearest the sink are all non-prioritized items. Robots will have to forage a large portion the non-prioritized items between the sink and the centre of the environment, in order to reach the high density of prioritized items at the centre of the environment. 

Figure~\ref{fig:gaussianhighdensityperformancehoneybee} shows the efficiency of foraging prioritized items $E_P$, the efficiency of foraging non-prioritized items $E_{NP}$, as well as the specialization ratio, $\tau$, for the honey bee algorithm, for each 200 time steps, on the Gaussian environment described above. The specialization ratio $\tau$ starts at 0.8 and then very quickly decreases to near 0 in about 200 time steps. The $E_{NP}$, increases very quickly after 200 time steps, since most of the robots are foraging non-prioritized items (since $\tau$ decreases to near 0). After around 800 time steps, $\tau$ increases from near 0 to just above 0.7, followed by a sharp increase in $E_P$, suggesting that the non-prioritized items have been cleared and the concentration of prioritized items in the centre have been reached, , which resulted in more robots switching to forage prioritized items and a greater efficiency of foraging the prioritized items.

Figure~\ref{fig:gaussianhighdensityperformancenaive} shows the efficiency of foraging prioritized items $E_P$ and the efficiency of foraging non-prioritized items $E_{NP}$, as well as the specialization ratio, $\tau$, for the Na\"ive algorithm, for each 200 time steps, on the Gaussian environment described above. The swarm specialization, $\tau$, stays constant, since the Na\"ive algorithm does not enable robots to switch their specialization. As a result, the increase of $E_{NP}$ was slow because only a few robots could forage the non-prioritized items, since $\tau=0.8$. The non-prioritized were obstacles in the way of reaching the prioritized items in the environment centre. As a result of the swarm's slowness in clearing the non-prioritized items, $E_P$ also remains low since foraging of prioritized items was slowed by the need to navigate around unforaged non-prioritized items. The behaviour for the Desert ant algorithm was similar to that of the Na\"ive algorithm, except final efficiency was greater for the Desert ant algorithm.

Figure~\ref{fig:gaussianhighdensityperformancehoneybee} shows that final $E_P$ for the Honey bee algorithm was 0.9, while Figure~\ref{fig:gaussianhighdensityperformancenaive} shows that the final $E_P$ for the Na\"ive algorithm was only 0.3. Since the Honey bee algorithm adapts $\tau$, the Honey bee algorithm shows an increased ability to forage obstacles (the non-prioritized items), in order to more easily access hard to reach prioritized items. As a result, the Honey bee algorithm is more flexible too different environment distributions, than the Na\"ive algorithm.

Figure~\ref{fig:uniformhighdensityperformancehoneybee} shows the efficiency of foraging prioritized items $E_P$, the efficiency of foraging non-prioritized items $E_{NP}$, as well as the specialization ratio, $\tau$, for the honey bee algorithm, for each 200 time steps, on a Uniform environment, with a similar configuration to the environment in Figure~\ref{fig:gaussianhighdensityenv}. The specialization ratio fluctuates randomly between 0.4 and 0.7, while the rate of foraging efficiency, $E_P$ and $E_{NP}$ remains constant throughout the experiment. The random fluctuation of $\tau$ seems reasonable, given that the environment distribution was also random.

The Desert ant algorithm outperforms the Na\"ive algorithm in terms of flexibility over environment distributions, since the Desert ant algorithm uses site fidelity, as discussed in Section~\ref{desertantforaging}, enabling the Desert ant to more efficiently return to the high concentrations of prioritized items.

\section{Scalability}
\label{results:scalability}

This section discusses the scalability of each algorithm. Section~\ref{results:swarmscalability} discusses scalability of each algorithm, in terms of swarm density, $SS$, as defined Section~\ref{swarmsizescalability} while Section~\ref{results:problemscalability} discusses the scalability of each algorithm, in terms of the complexity of the problem, $PS$, as defined in Section~\ref{setup:problemscalability}.

\subsection{Swarm scalability}
\label{results:swarmscalability}
According to Table~\ref{table:swarmscalability} and Figure~\ref{fig:swarmscalability}, that present the swarm density scalability $SS$ of each algorithm, the Na\"ive algorithm was the most scalable. The Desert ant and Honey bee algorithms show similar scalability. The Honey bee algorithm at lower densities appears to be more scalable than the Desert ant algorithm, but at the higher densities, $SS$ of the Desert ant algorithm was greater than the Honey bee algorithm. %That doesn't make sense

Figure~\ref{fig:swarmscalability} also plots ideal linear scalability, where the increase in swarm density is directly proportional to the increase in efficiency. The performance of all algorithms was sub-linear. In Section~\ref{swarmsizescalability}, increased inter-robot interference was highlighted as a major factor impacting swarm scalability and thus one can conclude that the reason for sub-linear performance was because all algorithms suffer from increased inter-robot interference as swarm size increases

To understand why the Desert ant and Honey bee algorithm were less scalable than the Na\"ive algorithm, consider the following:

The Na\"ive algorithm, being the most simple foraging algorithm, has no mechanism to enable the swarm to exploit high quality sites of prioritized items and can only locate items by randomly exploring the environment. Both the Desert ant algorithm and the Honey bee algorithm have mechanisms to exploit high quality areas: The Desert ant algorithm uses site fidelity and the Honey bee algorithm uses recruitment to exploit high quality sites. 

Suppose that there exists a single high quality site in an environment. Using site-fidelity and recruitment, the Desert ant and Honey bee algorithms can exploit that high quality area. In exploiting that high quality site, the path between the sink and the high-quality site becomes more congested as more robots share the path between the sink and the high quality area. The increased congestion on that path will cause more inter-robot interference, but due to the focused efforts, the exploitation will still improve performance overall, compared to the Na\"ive algorithm, at low swarm densities. However, as swarm density increases, the congestion on the route between the high quality site and the sink, will increase, hindering the overall efficiency due to increased inter-robot interference. It follows that the Desert ant algorithm and Honey bee algorithm are less scalable in terms of swarm density, than the Na\"ive algorithm, due to the increased inter-robot interference, as a result of exploitation of high quality sites.

The recruitment mechanism used by the Honey bee algorithm is a more extreme form of exploitation than site fidelity used by the Desert ant algorithm, since scouts recruit groups of robots to forage single areas. On the other hand, when using site fidelity, the high quality site is only foraged by the robot that found it. Considering that the recruitment mechanism is more exploitative than the site fidelity mechanism, one would expect the Honey bee algorithm to be much less scalable than the Desert ant algorithm, but that is not evidential in Table~\ref{table:swarmscalability}. Instead, the Honey bee algorithm performed slightly better than the Desert ant algorithm, according to Table~\ref{table:swarmscalability}, for everything except the extremely high values of $c$. 

To explain the Honey bee algorithm's ability to outperform the Desert ant algorithm at most swarm densities, one can look to the Honey bee algorithm's the division of labour mechanism, described in Section~\ref{honeybeeforaging}. The division of labour mechanism will cause an active forager robot to return to the sink if that robot can't find an item for a maximum amount of time. The inactive forager robot waits at the sink, until the inactive forager robot is recruited by a scout robot. Section~\ref{background:divisionoflabour:robotswarm} discussed that a mechanism of division of labour, which could adjust the number of robots actively foraging to an appropriate amount, would result in decreased levels of inter-robot interference, and increased swarm scalability.

In order to determine whether the slight improvement in scalability of the Honey bee algorithm over the Desert ant algorithm can be attributed to the discussed division of labour mechanism, the average time spent by robots, in the waiting state is plotted for different values of $c$ in Figure~\ref{swarmscalabilitywaitingtime}. It is clear from Figure~\ref{swarmscalabilitywaitingtime} that the robots spend a significant portion of time in the waiting state. However the time spent in the waiting state, decreases as swarm density increases. This result is counter-intuitive, because an appropriately functioning division of labour mechanism would lead to an increase of average time in the waiting as swarm density increases, due to increases in inter-robot interference. 

% need to talk about amount of recruitment that occurs

\begin{table}[]
\centering
\caption{Swarm scalability, $SS$, for each swarm density, $c$, for each algorithm.}
\label{table:swarmscalability}
\begin{tabular}{@{}lllllll@{}}
\toprule
\textbf{$c$}            & \textbf{0.1} & \textbf{0.3}         & \textbf{0.5}         & \textbf{0.7}         & \textbf{1}           \\ \midrule
\textbf{Na\"ive}    & 1   & 2.148309055 & 2.95067493  & 3.567754813 & 4.25529855  \\
\textbf{Desert ant} & 1   & 1.972768821 & 2.604500744 & 3.05833543  & 3.555516648 \\
\textbf{Honey bee}  & 1   & 2.067364168 & 2.706034502 & 3.119174449 & 3.532352867 \\ \bottomrule
\end{tabular}
\end{table}

\begin{figure}[!htb]
\centering
\small
\resizebox{\textwidth}{!}{\input{chapters/chapter6/graphs/scalability/swarmscalability.tex}}
\caption{Swarm Scalability, $SS$, for each swarm density $c$, for each algorithm, as well as linear scalability as swarm density increases.}
\label{fig:swarmscalability}
\end{figure}

\begin{figure}[!htb]
\centering
\small
\resizebox{\textwidth}{!}{\input{chapters/chapter6/graphs/scalability/swarm-scalability-waitingtime.tex}}
\caption{Average time in waiting state, $t_{wait}$, for each swarm density $c$, for the Honey bee algorithm}
\label{fig:swarmscalabilitywaitingtime}
\end{figure}

%TODO: Come back here

\subsection{Problem scalability}
\label{results:problemscalability}

Figure~\ref{fig:problemscalability} plots the problem scalability performance measure $PS$ (described in Section~\ref{setup:problemscalability}) for each algorithm, with values given in Table~\ref{table:problemscalability}. The figure includes a plot of "Expected scalability". "Expected scalability" is the expected values for $PS$, using the assumption that foraging efficiency would degrade as the problem size increases. All algorithm's outperform the expected scalability and thus problem scalability for all algorithms is super-linear.

According to Figure~\ref{fig:problemscalability}, the Honey bee algorithm is the most scalable in terms of $PS$, followed by the Na\"ive algorithm, with the Desert ant algorithm having the worst scalability. %WHY CAN I SAY THAT?

As stated in Section~\ref{setup:problemscalability}, the inability for an algorithm to scale with regards to the size of the problem, is due to ineffectively handling the increased environmental interference that occurs in problems of greater size and complexity.

The Na\"ive algorithm is more scalable than the Desert ant algorithm. The Desert ant algorithm is the same as the Na\"ive algorithm, except that the Desert ant algorithm employs site fidelity, described in Section~\ref{desertantforaging}, to enable a robot to return to a previously foraged site. Rationally, the site fidelity mechanism, directly or indirectly, must be the reason for the decreased scalability of the Desert ant algorithm. To understand why the site fidelity mechanism is negatively influencing scalability, consider the following scenario: A Desert ant robot employs a random walk through a complex environment, as shown in red in Figure~\ref{fig:desertantsitefidelity}. The random walk leads the Desert ant robot to a hard-to-reach source of prioritized items. The Desert ant robot stores the PI vector, shown in blue on the figure, which is needed to return back to the site after offloading the loaded item at the sink. The next time the Desert ant wants to return to the previous site, the robot will still need to perform the same obstacle avoidance in order to navigate around the obstacles to return to the previously foraged site, since the PI vector only consists of an overall heading and distance to the site. As is evident on Figure~\ref{fig:desertantsitefidelity}, there may exist an easier to reach site for prioritized items, but the Desert ant robot will wait time, continuing to forage the hard to locate source of items. On the other hand the Na\"ive algorithm, due to the fact it can't exploit previously location areas using site fidelity, will not return to the hard to find site and is more likely to randomly find the prioritized resource site that is nearer the sink (indicated by the green path). The time spent on relocating hard to access sites, in more complex environments, can slow the Desert ant algorithm down.

\begin{figure}[!htb]
\centering
\includegraphics[width=0.75\textwidth]{chapters/chapter6/figures/problem-scalability-desertant.png}
\caption{Illustration of the inefficiencies of Desert ant algorithm's site fidelity in dense environments. Solid areas are non-prioritized items, white areas are free cells and shaded areas are prioritized items. The red path is a hypothetical random walk performed by a robot, the blue path is the PI vector for the red random walk, and the green path is an alternative random walk.}
\label{fig:desertantsitefidelity}
\end{figure}

The Honey bee algorithm uses site fidelity, and also communicates those sites to others. Despite the use of similar site fidelity mechanism to the Desert ant algorithm, the Honey bee algorithm is the most scalable. The reason why the site fidelity of the Honey bee algorithm does not impact the scalability, can be attributed the ability of the Honey bee algorithm to adapt the swarm specialization ratio, $\tau$, to focus on foraging dense areas of obstacles, rather than having to expensively navigate around the obstacles. The ability of the Honey bee algorithm to concentrate on clearing obstacles in highly dense environments, will increase overall ease of access to the high quality sites, as discovered in Section~\ref{results:flexibility:environmentdistribution}. Thus efficiency of the Honey bee algorithm in highly dense environments s improved. Therefore, the Honey bee algorithm is the most scalable in terms of the problem size and complexity.

\begin{table}[]
\centering
\caption{Problem Scalability, $PS$, for each environment density $p$, for each algorithm}
\label{table:problemscalability}
\begin{tabular}{@{}llllll@{}}
\toprule
\textbf{$p$}                  & \textbf{0.05} & \textbf{0.2        } & \textbf{0.5}         & \textbf{0.7}         & \textbf{0.9}         \\ \midrule
\textbf{Desert ant}           & 1    & 0.487816741 & 0.231581619 & 0.181686679 & 0.167953071 \\
\textbf{Honey bee}            & 1    & 0.602283728 & 0.283264856 & 0.216749784 & 0.195686487 \\
\textbf{Na\"ive}              & 1    & 0.501722909 & 0.256758663 & 0.195206738 & 0.174522486 \\
\textbf{Expected} & 1    & 0.25        & 0.1         & 0.071428571 & 0.055555556 \\ \bottomrule
\end{tabular}
\end{table}

\begin{figure}[!htb]
\centering
\resizebox{\textwidth}{!}{\input{chapters/chapter6/graphs/scalability/problemscalability.tex}}
\caption{Problem Scalability, $PS$, for each environment density $p$, for each algorithm}
\label{fig:problemscalability}
\end{figure}

\section{Robustness}
\label{results:robustness}
% describe fault tolerance, and provide rational arguments as to why it would be more or less 
As discussed in Section~\ref{robustness}, robot swarms achieve robustness by exhibiting the properties of redundancy, multiplicity of sensing and decentralized coordination. This study does not perform an empirical robustness study to specifically address how fault tolerant each algorithm is, instead this section provides rational arguments supported by empirical evidence to discuss each  algorithm's capability for robustness. Section~\ref{results:redundancy} discusses robustness in terms of redundancy of each algorithm, and Section~\ref{results:decentralizedcoordination} discusses robustness in terms of decentralized coordination.

\subsection{Redundancy}
\label{results:redundancy}
For each of our experiments, each swarm is configured with an initial swarm specialization ratio, as discussed in Chapter~\ref{chap:experiment} to enable a portion of robots to forage prioritized items and the another portion to forage non-prioritized items. 

If a portion of robots in a swarm malfunction or are destroyed, then the swarm specialization ratio could be affected. As shown in Section~\ref{results:flexibility}, the foraging efficiency of the Na\"ive and Desert ant algorithms were effected by the initial swarm specialization ratio $\tau$. It follows that if the swarm specialization ratio is unexpectedly changed, during the swarm experiment, one would expect changes to foraging efficiency that would persist for the swarm's lifetime. In particular, consider the following extreme scenarios: 

Suppose all the robots which were foraging for prioritized items (for some $\tau > 0$) are destroyed or malfunction (thus $\tau=0$). Foraging efficiency would drop to 0 since there do not exist any robots to forage prioritized items. Similarly, consider an environment where all prioritized items are blocked by non-prioritized items, and $\tau < 1$ . If all non-prioritized robots suffer a malfunction or are destroyed, then $\tau=1$ and there would exist no robots to forage non-prioritized items, and foraging efficiency, $E_P$, would drop to 0. 

As shown in Section~\ref{results:flexibility}, the Honey bee algorithm experiences little change to efficiency, when $\tau_0$ is varied. The Honey bee algorithm adapted the swarm specialization ratio, $\tau$, over time. It follows that, in the above scenarios, the Honey bee algorithm would be able to re-adapt the swarm specialization ratio, in order to replenish the robots that were destroyed. 

The robots in the Honey bee algorithm are homogeneous, in that every robot in the swarm has the ability to take on any of the roles required for the algorithm to function (scout, unemployed forager, employed forager), as well as adapt to forage either prioritized and non-prioritized items. It follows that the Honey bee algorithm is more redundant than the Desert ant and Na\"ive algorithms.

\subsection{Decentralized Co-ordination}
\label{results:decentralizedcoordination}

%Some sort of intro

The Desert ant and Na\"ive algorithm do not have an explicit coordination mechanism between individuals of a swarm. Any co-ordination that could emerges would be entirely decentralized. 

On the other hand, the Honey bee algorithm uses communication as a coordination mechanism, in order to recruit foragers to areas with a high density of prioritized items, as described in Section~\ref{honeybeeforaging}. If the scout robots experiences a fault in evaluating the quality of a site (for instance, detecting that a site is of high quality, when it is actually site of poor quality), then foragers would be recruited to forage sites of low quality, incorrectly. Only a few individuals (the scouts), can coordinate the swarm and therefore any faults in the scout robots, can negatively influence effect the efficiency of the entire swarm. The co-ordination mechanisms of the Honey bee algorithm are not entirely decentralized.

Table~\ref{averagetimerecruitment} shows the average time steps, per robot, per item foraged, that were spent performing recruitment, for the honey bee algorithm, in each environment distribution, for each environment item type ratio. 

In a uniformly distributed environment, with a low ratio of prioritized items, sites with a high quality do not exist, as the prioritized items would be scarce and scattered. However, Table~\ref{averagetimerecruitment} shows that each robot spent, on average, more than a 10th of the total duration of the experiment broadcasting site quality to other robots in uniform environments, when $r$ was between 0 and 0.25. This means that the scouts were recruiting other robots to forage areas that were not of a high quality. The fact that scouts can mislead the swarm to foraging sites with low quality, shows that the honey bee algorithm is less robust.

\begin{table}[]
\centering
\caption{Average time steps, per robot, that were spent performing recruitment, for the Honey bee algorithm, in each environment distribution, for each environment item type ratio $r$.}
\label{averagetimerecruitment}
\begin{tabular}{@{}lllll@{}}
\toprule
$r$            & \textbf{clustered} & \textbf{gaussian} & \textbf{uniform} & \textbf{vein} \\ \midrule
\textbf{0}        & 0.163853094        & 0.162636914       & 0.159305395      & 0.163353443   \\
\textbf{0.2}      & 0.119486333        & 0.152139262       & 0.11962912       & 0.160737113   \\
\textbf{0.25}     & 0.126752914        & 0.144484389       & 0.127568794      & 0.158813789   \\
\textbf{0.333333} & 0.140492087        & 0.135243974       & 0.139460537      & 0.151803907   \\
\textbf{0.5}      & 0.161644793        & 0.15738657        & 0.16335568       & 0.168543223   \\
\textbf{0.666667} & 0.181659692        & 0.174940591       & 0.183477822      & 0.151701447   \\
\textbf{0.75}     & 0.179285021        & 0.177420259       & 0.183721153      & 0.171862739   \\
\textbf{0.8}      & 0.182807781        & 0.182650316       & 0.186144899      & 0.190969001   \\
\textbf{1}        & 0.167397088        & 0.172990294       & 0.163048904      & 0.219223401   \\ \bottomrule
\end{tabular}
\end{table}

\section{Summary}
\label{results:summary}

This chapter presented the results of the experiments and performed analysis of the major properties of swarm robotics, for each algorithm. The results were discussed around four axes: efficiency, flexibility, robustness and scalability. 

Section~\ref{results:efficiency} presented an overview of foraging efficiency of each algorithm. The results showed that the Honey bee algorithm was the most efficient over all environments and swarm configurations, while the Desert ant was the next most efficient and the Na\"ive algorithm was the least efficient.

Section~\ref{results:flexibility} analysed the flexibility of each algorithm. Flexibility was analysed in terms of flexibility over environments prioritized item ratio, $F_r$, and flexibility over environment distribution type, $F_{ED}$. 

Section~\ref{results:prioritizeditemratio} concluded that the Honey bee algorithm was the most flexible in terms of prioritized item ratio. It was shown that the Honey bee algorithm's flexibility is a result of Honey bee algorithm's ability to adapt the specialization ratio $\tau$, via the Honey bee algorithm's division of labour mechanism. The division of labour mechanism allowed the Honey bee robots to more efficiently forage an environment for any given environment item ratio $r$. The Na\"ive algorithm was more flexible than the Desert ant algorithm, in terms of environment item distribution. The Na\"ive algorithm's perceived flexibility is attributed to the fact that the Na\"ive algorithm suffers far lower efficiency across all environment item ratios, suggesting that it appears flexible since it performs equally bad across all values of $r$, unable to exploit any differences between the environments. 

Section~\ref{results:flexibility:environmentdistribution} concluded that the Honey bee algorithm is the most flexible, in terms of environmental distribution, followed by the Desert ant algorithm and lastly the Na\"ive algorithm. The Honey bee algorithm was determined to be more flexible, due to it's ability to adapt the specialization ratio to better suit the types of items that are reachable by the swarm. The adaptation of specialization ratio allowed the Honey bee swarm to focus on foraging non-prioritized when only non-prioritized items were reachable, and then adjust the ratio to focus on foraging prioritized items when prioritized items were reachable. The Desert ant and Na\"ive algorithms, without the ability to adjust $\tau$ to more effectively forage the ratio of reachable objects, are less flexible than the Honey bee algorithm.
  The Na\"ive algorithm's perceived flexibility over environment distribution, compared to the Desert ant algorithm, was attributed to the same reasons as determined by Section~\ref{results:prioritizeditemratio}. 
  
Section~\ref{results:scalability} evaluated scalability in terms of swarm scalability, $SS$ and $PS$. Section~\ref{results:swarmscalability} determined that the scalability of all algorithms, in terms of swarm scalability, was sub-linear. More specifically, the Na\"ive algorithm was the most scalable in terms of swarm density, and then the Desert ant and Honey bee algorithms which exhibited similar scalability. The Desert ant algorithm's poor performance, compared to the Na\"ive algorithm was attributed the Desert ant algorithm's use of site fidelity. A rational argument was presented that argued the Desert ant algorithm's site fidelity increased inter-robot interference, which resulted in poor efficiency when swarm density was high. The Honey bee algorithm was shown to be slightly more scalable than the Desert ant algorithm, due to the Honey bee algorithm's attempt to regulate the number of active foragers by division of labour. The difference in swarm scalability between the Desert ant algorithm and Honey bee algorithm was very small, suggesting that the regulation of active foragers was not functioning very well. The Honey bee algorithm's ability to regulate the number of active foragers as swarm densities increase, was shown to be ineffective. 

Section~\ref{results:problemscalability} determined that the Honey bee algorithm is the most scalable in terms of problem scalability, followed by the Na\"ive algorithm, and lastly the Desert ant algorithm. The discussion showed that the Desert ant's performed comparatively worse than the Na\"ive algorithm in terms of problem scalability, due to the Desert ant algorithm's use of site fidelity to exploit good search areas. The section determined the Na\"ive algorithm's ability to explore more than the Desert ant algorithm, resulted in better problem scalability. The Honey bee algorithm was the most scalable in terms of problem scalability. The problem scalability of the Honey bee algorithm can be attributed to the ability of the Honey bee algorithm to adapt $\tau$ to help clear non-prioritized items, which resulted in lower inter-robot and environmental interference.

Section~\ref{results:robustness} addressed robustness of each of the algorithms, in terms of redundancy and decentralized co-ordination. Section \ref{results:redundancy} showed that the Honey bee algorithm has the highest redundancy, since the swarm is homogeneous. The Honey bee swarm is homogeneous as the robots can switch specialization, rather than being set to forage only a specific item type. The Desert ant algorithm and Na\"ive algorithm robots can only forage a single item type, which is pre-configured and thus their swarms are heterogeneous, and thus the swarms are less redundant.

Section~\ref{results:decentralizedcoordination} determined that the Desert ant and Na\"ive algorithm are the most robust in terms of decentralized coordination, since neither algorithm employ a coordination mechanism between robots of the swarm. The Honey bee algorithm was determined to be the least robust in terms of decentralized coordination. The Honey bee algorithm's coordination mechanism was sensitive to faults in certain individuals where invalid information was communicated to the swarm and the invalid information impacted efficiency.

%DONT THINK THIS GOES HERE%
Taking the discussion of the flexibility, scalability, and robustness of each algorithm back to foraging efficiency: The Honey bee algorithm exhibited a high level of flexibility, problem scalability, and redundancy, resulting in greater overall efficiency than the Desert ant algorithm and Na\"ive algorithm. On the other hand, despite the Na\"ive algorithm exhibiting better scalability than the Desert ant algorithm, the Desert ants algorithm's ability to exploit high quality areas, resulted in greater average performance than the Na\"ive algorithm.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%1%%%%%%%
